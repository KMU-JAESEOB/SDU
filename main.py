# main.py - ì™„ì „ ê°ì²´ì§€í–¥ SDA-U ì•Œê³ ë¦¬ì¦˜
"""
ğŸ¯ ì™„ì „ ê°ì²´ì§€í–¥ SDA-U (Selective Domain Adaptation with Unlearning) ì•Œê³ ë¦¬ì¦˜

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. ì™„ì „í•œ ê°ì²´ì§€í–¥ ì„¤ê³„ (í´ë˜ìŠ¤ ê¸°ë°˜)
2. ì„¤ì • íŒŒì¼ ë¶„ë¦¬ (config.json)
3. ì¤‘ë³µ í•¨ìˆ˜ í†µí•© ë° ì œê±°
4. ìœ ì§€ë³´ìˆ˜ì„± ë° í™•ì¥ì„± í–¥ìƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
import copy
import argparse
import os
import json
import random
import sys
from pathlib import Path
import time
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass

# ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•œ ë²„í¼ë§ í•´ì œ
sys.stdout.reconfigure(line_buffering=True)

def flush_print(*args, **kwargs):
    """ì¦‰ì‹œ ì¶œë ¥ë˜ëŠ” print í•¨ìˆ˜"""
    print(*args, **kwargs)
    sys.stdout.flush()

# ë°ì´í„° ë¡œë”
from office31_loader import Office31Manager
from officehome_loader import OfficeHomeLoader

# GPU ì„¤ì •
try:
    from gpu_config import setup_gpu_optimizations, get_gpu_info
    GPU_OPTIMIZED = True
except ImportError:
    GPU_OPTIMIZED = False

# ì „ì—­ ë³€ìˆ˜
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

@dataclass
class ExperimentResults:
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    initial_target_acc: float
    final_target_acc: float
    best_target_acc: float
    best_epoch: int
    improvement: float
    best_improvement: float
    unlearning_count: int
    total_epochs: int
    performance_history: Dict
    model_paths: Dict[str, str]

class SDAUConfig:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "config.json"):
        """ì„¤ì • íŒŒì¼ ë¡œë”©"""
        self.config_path = config_path
        self.config = self._load_config()
        self._validate_config()
    
    def _load_config(self) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë”©"""
        if not os.path.exists(self.config_path):
            raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config_path}")
        
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _validate_config(self):
        """ì„¤ì • íŒŒì¼ ê²€ì¦"""
        required_sections = ['model', 'training', 'target_selection', 
                           'influence_calculation', 'unlearning', 'paths']
        
        for section in required_sections:
            if section not in self.config:
                raise ValueError(f"í•„ìˆ˜ ì„¤ì • ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤: {section}")
    
    def get(self, section: str, key: str = None, default=None):
        """ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°"""
        if key is None:
            return self.config.get(section, default)
        return self.config.get(section, {}).get(key, default)
    
    def get_num_classes(self, dataset: str) -> int:
        """ë°ì´í„°ì…‹ë³„ í´ë˜ìŠ¤ ìˆ˜ ë°˜í™˜"""
        return self.config['model']['num_classes'].get(dataset, 31)
    
    def get_domains(self, dataset: str) -> List[str]:
        """ë°ì´í„°ì…‹ë³„ ë„ë©”ì¸ ëª©ë¡ ë°˜í™˜"""
        return self.config['datasets'].get(dataset, {}).get('domains', [])

class ModelManager:
    """ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
        self.device = device
    
    def create_model(self, num_classes: int) -> nn.Module:
        """ëª¨ë¸ ìƒì„±"""
        architecture = self.config.get('model', 'architecture')
        pretrained = self.config.get('model', 'pretrained')
        
        if architecture == 'resnet50':
            from torchvision.models import resnet50, ResNet50_Weights
            weights = ResNet50_Weights.DEFAULT if pretrained else None
            model = resnet50(weights=weights)
            model.fc = nn.Linear(model.fc.in_features, num_classes)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜: {architecture}")
        
        return model.to(self.device)
    
    def save_model(self, model: nn.Module, save_path: str, metadata: Dict = None):
        """ëª¨ë¸ ì €ì¥"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        save_dict = {
            'model_state_dict': model.state_dict(),
            'config': self.config.config,
            'timestamp': time.time()
        }
        
        if metadata:
            save_dict.update(metadata)
        
        torch.save(save_dict, save_path)
        flush_print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")
    
    def load_model(self, model: nn.Module, load_path: str) -> Dict:
        """ëª¨ë¸ ë¡œë”©"""
        if not os.path.exists(load_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
        
        checkpoint = torch.load(load_path, map_location=self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        flush_print(f"ğŸ“¥ ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {load_path}")
        return checkpoint

class DataManager:
    """ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
        self.data_root = self.config.get('paths', 'data_root')
    
    def load_dataset(self, dataset: str, source_domain: str, target_domain: str, 
                    batch_size: int) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader, int]:
        """ë°ì´í„°ì…‹ ë¡œë”©"""
        if dataset == 'Office31':
            return self._load_office31(source_domain, target_domain, batch_size)
        elif dataset == 'OfficeHome':
            return self._load_officehome(source_domain, target_domain, batch_size)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹: {dataset}")
    
    def _load_office31(self, source_domain: str, target_domain: str, 
                      batch_size: int) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader, int]:
        """Office31 ë°ì´í„°ì…‹ ë¡œë”©"""
        manager = Office31Manager(root=self.data_root)
        
        source_train_dataset, source_test_dataset = manager.load_domain_data(source_domain)
        target_train_dataset, target_test_dataset = manager.load_domain_data(target_domain)
        
        source_train_loader = DataLoader(source_train_dataset, batch_size=batch_size, shuffle=True)
        source_test_loader = DataLoader(source_test_dataset, batch_size=batch_size, shuffle=False)
        target_train_loader = DataLoader(target_train_dataset, batch_size=batch_size, shuffle=True)
        target_test_loader = DataLoader(target_test_dataset, batch_size=batch_size, shuffle=False)
        
        return source_train_loader, source_test_loader, target_train_loader, target_test_loader, 31
    
    def _load_officehome(self, source_domain: str, target_domain: str, 
                        batch_size: int) -> Tuple[DataLoader, DataLoader, DataLoader, DataLoader, int]:
        """OfficeHome ë°ì´í„°ì…‹ ë¡œë”©"""
        loader = OfficeHomeLoader(root=self.data_root)
        
        # OfficeHome ë¡œë”ê°€ ì´ì œ DataLoaderë¥¼ ì§ì ‘ ë°˜í™˜ (collate_fn í¬í•¨)
        source_train_loader, source_test_loader = loader.load_domain_data(source_domain, batch_size)
        target_train_loader, target_test_loader = loader.load_domain_data(target_domain, batch_size)
        
        return source_train_loader, source_test_loader, target_train_loader, target_test_loader, 65

class TargetSampleSelector:
    """íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„ í´ë˜ìŠ¤ - AlignSet + ëŠ¥ë™í•™ìŠµ í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
    
    def select_samples(self, model: nn.Module, target_train_loader: DataLoader, 
                      num_classes: int) -> List[Tuple]:
        """íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„ - AlignSet + ëŠ¥ë™í•™ìŠµ í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§"""
        method = self.config.get('target_selection', 'selection_method')
        
        if method == 'hybrid_alignset_active':
            return self._select_hybrid_alignset_active(model, target_train_loader)
        elif method == 'random':
            return self._select_random(target_train_loader)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ ë³„ ë°©ë²•: {method}")
    
    def _select_hybrid_alignset_active(self, model: nn.Module, target_train_loader: DataLoader) -> List[Tuple]:
        """AlignSet + ëŠ¥ë™í•™ìŠµ í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ê¸°ë°˜ ì„ ë³„"""
        num_samples = self.config.get('target_selection', 'num_samples')
        lambda_u = self.config.get('target_selection', 'lambda_utility', 0.7)
        beta = self.config.get('target_selection', 'beta_uncertainty', 0.3)
        
        print(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„ ì¤‘... (ëª©í‘œ: {num_samples}ê°œ)")
        
        model.eval()
        
        # ëª¨ë“  íƒ€ê²Ÿ ìƒ˜í”Œ ìˆ˜ì§‘ ë° íŠ¹ì§• ì¶”ì¶œ
        all_samples = []
        all_features = []
        all_utilities = []
        all_uncertainties = []
        
        with torch.no_grad():
            for data, target in target_train_loader:
                for i in range(len(data)):
                    x = data[i].unsqueeze(0).to(device)
                    
                    # íŠ¹ì§• ì¶”ì¶œ (ë§ˆì§€ë§‰ FC ì¸µ ì´ì „)
                    if hasattr(model, 'fc'):
                        # ResNet50ì˜ ê²½ìš° FC ì¸µ ì „ê¹Œì§€ì˜ íŠ¹ì§• ì¶”ì¶œ
                        modules = list(model.children())[:-1]  # FC ì¸µ ì œì™¸
                        feature_extractor = nn.Sequential(*modules)
                        features = feature_extractor(x)
                        features = features.view(features.size(0), -1)
                    else:
                        features = x.view(x.size(0), -1)
                    
                    # ì „ì²´ ì˜ˆì¸¡
                    output = model(x)
                    probs = F.softmax(output, dim=1)
                    
                    # ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±
                    pseudo_label = torch.argmax(probs, dim=1)
                    
                    # ìœ ìš©ì„± ê³„ì‚° (ì˜ì‚¬ ë ˆì´ë¸”ì— ëŒ€í•œ ì†ì‹¤ì˜ ìŒìˆ˜)
                    utility = -F.cross_entropy(output, pseudo_label).item()
                    
                    # ë¶ˆí™•ì‹¤ì„± ê³„ì‚° (ì—”íŠ¸ë¡œí”¼)
                    uncertainty = -(probs * torch.log(probs + 1e-8)).sum().item()
                    
                    all_samples.append((data[i], target[i]))
                    all_features.append(features.cpu())
                    all_utilities.append(utility)
                    all_uncertainties.append(uncertainty)
        
        print(f"ğŸ“Š ì „ì²´ íƒ€ê²Ÿ ìƒ˜í”Œ: {len(all_samples)}ê°œ")
        
        # ì˜ì‚¬ ë¼ë²¨ ì¶”ê°€ ê³„ì‚°
        all_pseudo_labels = []
        with torch.no_grad():
            for data, target in [(s[0], s[1]) for s in all_samples]:
                x = data.unsqueeze(0).to(device)
                output = model(x)
                probs = F.softmax(output, dim=1)
                pseudo_label = torch.argmax(probs, dim=1).item()
                all_pseudo_labels.append(pseudo_label)
        
        # ì ì§„ì  ì„ ë³„ (ê·¸ë¦¬ë”” ë°©ì‹)
        selected_indices = []
        selected_features = []
        selected_pseudo_labels = []
        
        for step in range(min(num_samples, len(all_samples))):
            best_score = float('-inf')
            best_idx = -1
            
            for i, (utility, uncertainty, features, pseudo_label) in enumerate(zip(all_utilities, all_uncertainties, all_features, all_pseudo_labels)):
                if i in selected_indices:
                    continue
                
                # 1. íŠ¹ì§• ê³µê°„ ë‹¤ì–‘ì„±
                if len(selected_features) == 0:
                    feature_diversity = 1.0  # ì²« ë²ˆì§¸ ìƒ˜í”Œ
                else:
                    # ì„ íƒëœ ìƒ˜í”Œë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„
                    max_similarity = 0.0
                    for selected_feat in selected_features:
                        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                        similarity = F.cosine_similarity(features, selected_feat, dim=1).item()
                        max_similarity = max(max_similarity, similarity)
                    feature_diversity = 1.0 - max_similarity
                
                # 2. ì˜ì‚¬ ë¼ë²¨ ë‹¤ì–‘ì„± (ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ ì„ í˜¸)
                if len(selected_pseudo_labels) == 0:
                    label_diversity = 1.0
                else:
                    same_label_count = sum(1 for label in selected_pseudo_labels if label == pseudo_label)
                    label_diversity = 1.0 - (same_label_count / len(selected_pseudo_labels))
                
                # 3. í˜¼í•© ë‹¤ì–‘ì„± (íŠ¹ì§• + ë¼ë²¨)
                diversity = 0.7 * feature_diversity + 0.3 * label_diversity
                
                # AlignSet ì ìˆ˜
                alignset_score = lambda_u * utility + (1 - lambda_u) * diversity
                
                # ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
                hybrid_score = alignset_score + beta * uncertainty
                
                if hybrid_score > best_score:
                    best_score = hybrid_score
                    best_idx = i
            
            if best_idx != -1:
                selected_indices.append(best_idx)
                selected_features.append(all_features[best_idx])
                selected_pseudo_labels.append(all_pseudo_labels[best_idx])
        
        selected_samples = [all_samples[i] for i in selected_indices]
        
        # í´ë˜ìŠ¤ë³„ ë¶„í¬ ì¶œë ¥ ì¶”ê°€
        class_counts = {}
        for _, label in selected_samples:
            label_item = label.item() if hasattr(label, 'item') else int(label)
            class_counts[label_item] = class_counts.get(label_item, 0) + 1
        
        print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ì„ ë³„ ì™„ë£Œ: {len(selected_samples)}ê°œ")
        print(f"ğŸ“Š í´ë˜ìŠ¤ë³„ ì„ ë³„ëœ ìƒ˜í”Œ ë¶„í¬:")
        for class_id in sorted(class_counts.keys()):
            print(f"   í´ë˜ìŠ¤ {class_id:2d}: {class_counts[class_id]:3d}ê°œ")
        
        return selected_samples
    
    def _select_random(self, target_train_loader: DataLoader) -> List[Tuple]:
        """ëœë¤ ì„ ë³„"""
        num_samples = self.config.get('target_selection', 'num_samples')
        
        all_samples = []
        for data, target in target_train_loader:
            for i in range(len(data)):
                all_samples.append((data[i], target[i]))
        
        total_samples = len(all_samples)
        select_count = min(num_samples, total_samples)
        
        random.seed(42)
        selected_samples = random.sample(all_samples, select_count)
        
        print(f"âœ… ëœë¤ ì„ ë³„ ì™„ë£Œ: {len(selected_samples)}ê°œ / {total_samples}ê°œ")
        return selected_samples

class InfluenceCalculator:
    """ì˜í–¥ë„ ê³„ì‚° í´ë˜ìŠ¤ - ì˜í–¥ë„ ê¸°ë°˜ í•„í„°ë§"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
    
    def compute_influence_scores(self, model: nn.Module, source_loader: DataLoader, 
                               target_samples: List[Tuple]) -> Tuple[List[Tuple], List[float]]:
        """ì˜í–¥ë„ ê¸°ë°˜ ìœ í•´ ì†ŒìŠ¤ ìƒ˜í”Œ í•„í„°ë§"""
        method = self.config.get('influence_calculation', 'method')
        num_samples = self.config.get('influence_calculation', 'num_samples')
        
        if method == 'influence_filtering':
            return self._compute_influence_filtering(model, source_loader, target_samples, num_samples)
        elif method == 'simple':
            return self._compute_simple_influence(model, source_loader, target_samples, num_samples)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜í–¥ë„ ê³„ì‚° ë°©ë²•: {method}")
    
    def _compute_influence_filtering(self, model: nn.Module, source_loader: DataLoader,
                                   target_samples: List[Tuple], num_samples: int) -> Tuple[List[Tuple], List[float]]:
        """ì˜í–¥ë„ ê¸°ë°˜ í•„í„°ë§ - íƒ€ê²Ÿ ì ì‘ì— í•´ë¡œìš´ ì†ŒìŠ¤ ìƒ˜í”Œ ì‹ë³„"""
        print(f"ğŸ”¬ ì˜í–¥ë„ ê¸°ë°˜ í•„í„°ë§ ì¤‘... (ìƒ˜í”Œ: {num_samples}ê°œ)")
        
        model.eval()
        damping = self.config.get('influence_calculation', 'damping', 0.01)
        lissa_iterations = self.config.get('influence_calculation', 'lissa_iterations', 10)
        
        # 1. íƒ€ê²Ÿ ë°°ì¹˜ì˜ í‰ê·  ì†ì‹¤ ê¸°ìš¸ê¸° ê³„ì‚°
        print("ğŸ“Š íƒ€ê²Ÿ ë°°ì¹˜ ê¸°ìš¸ê¸° ê³„ì‚° ì¤‘...")
        target_gradients = []
        
        for data, target in target_samples:
            data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
            
            model.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, target)
            
            grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)
            target_gradients.append([g.clone() for g in grad])
        
        # íƒ€ê²Ÿ í‰ê·  ê¸°ìš¸ê¸°
        avg_target_grad = []
        for i in range(len(target_gradients[0])):
            param_grads = [tg[i] for tg in target_gradients]
            avg_grad = torch.stack(param_grads).mean(dim=0)
            avg_target_grad.append(avg_grad)
        
        # 2. LiSSAë¡œ í—¤ì‹œì•ˆ ì—­í–‰ë ¬ ê·¼ì‚¬
        h_estimate = [g.clone() for g in avg_target_grad]
        
        for iteration in range(lissa_iterations):
            try:
                batch_data, batch_target = next(iter(source_loader))
                sample_idx = random.randint(0, len(batch_data) - 1)
                data = batch_data[sample_idx:sample_idx+1].to(device)
                target = batch_target[sample_idx:sample_idx+1].to(device)
                
                model.zero_grad()
                output = model(data)
                loss = F.cross_entropy(output, target)
                
                # í—¤ì‹œì•ˆ-ë²¡í„° ê³±
                hvp = self._compute_hessian_vector_product(model, loss, h_estimate)
                
                # LiSSA ì—…ë°ì´íŠ¸
                for j in range(len(h_estimate)):
                    h_estimate[j] = avg_target_grad[j] + h_estimate[j] - damping * hvp[j]
                    
            except Exception as e:
                print(f"âš ï¸ LiSSA ë°˜ë³µ ì¤‘ ì˜¤ë¥˜: {e}")
                break
        
        # 3. ì†ŒìŠ¤ ìƒ˜í”Œë³„ ì˜í–¥ë„ ê³„ì‚° I_up(z_i, D_T^batch)
        influence_scores = []
        source_samples = []
        harmful_count = 0
        
        sample_count = 0
        for batch_data, batch_target in source_loader:
            if sample_count >= num_samples:
                break
                
            for i in range(len(batch_data)):
                if sample_count >= num_samples:
                    break
                    
                data, target = batch_data[i].unsqueeze(0).to(device), batch_target[i].unsqueeze(0).to(device)
                
                try:
                    model.zero_grad()
                    output = model(data)
                    loss = F.cross_entropy(output, target)
                    
                    source_grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)
                    
                    # ì˜í–¥ë„ ê³„ì‚°: I_up = -âˆ‡L(D_T)^T * H^-1 * âˆ‡L(z_i)
                    influence = 0
                    for sg, ihvp in zip(source_grad, h_estimate):
                        influence += torch.sum(sg * ihvp).item()
                    
                    influence = -influence  # ë…¼ë¬¸ ê³µì‹ì— ë”°ë¥¸ ìŒìˆ˜
                    
                    # ìŒìˆ˜ ì˜í–¥ë„ = íƒ€ê²Ÿ ì ì‘ì— í•´ë¡œì›€
                    if influence < 0:
                        harmful_count += 1
                    
                    influence_scores.append(influence)
                    source_samples.append((batch_data[i], batch_target[i]))
                    sample_count += 1
                        
                except Exception as e:
                    print(f"âš ï¸ ì˜í–¥ë„ ê³„ì‚° ì‹¤íŒ¨ (ìƒ˜í”Œ {sample_count}): {e}")
                    continue
        
        print(f"âœ… ì˜í–¥ë„ í•„í„°ë§ ì™„ë£Œ: {harmful_count}ê°œ ìœ í•´ ìƒ˜í”Œ / {len(influence_scores)}ê°œ ì „ì²´")
        
        return source_samples, influence_scores
    
    def _compute_simple_influence(self, model: nn.Module, source_loader: DataLoader,
                                target_samples: List[Tuple], num_samples: int) -> Tuple[List[Tuple], List[float]]:
        """ê°„ë‹¨í•œ ì˜í–¥ë„ ê³„ì‚°"""
        model.eval()
        
        # íƒ€ê²Ÿ ìƒ˜í”Œë“¤ì˜ ì†ì‹¤ ê³„ì‚°
        target_losses = []
        for data, target in target_samples:
            data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
            with torch.no_grad():
                output = model(data)
                loss = F.cross_entropy(output, target)
                target_losses.append(loss.item())
        
        avg_target_loss = np.mean(target_losses)
        
        # ì†ŒìŠ¤ ìƒ˜í”Œë“¤ì˜ ì˜í–¥ë„ ê³„ì‚°
        influence_scores = []
        source_samples = []
        
        sample_count = 0
        for batch_data, batch_target in source_loader:
            if sample_count >= num_samples:
                break
                
            for i in range(len(batch_data)):
                if sample_count >= num_samples:
                    break
                    
                data, target = batch_data[i].unsqueeze(0).to(device), batch_target[i].unsqueeze(0).to(device)
                
                with torch.no_grad():
                    output = model(data)
                    loss = F.cross_entropy(output, target)
                    influence = loss.item() - avg_target_loss
                    
                influence_scores.append(influence)
                source_samples.append((batch_data[i], batch_target[i]))
                sample_count += 1
        
        return source_samples, influence_scores
    
    def _compute_hessian_vector_product(self, model: nn.Module, loss: torch.Tensor, 
                                      vector: List[torch.Tensor]) -> List[torch.Tensor]:
        """í—¤ì‹œì•ˆ-ë²¡í„° ê³± ê³„ì‚°"""
        grad = torch.autograd.grad(loss, model.parameters(), create_graph=True, retain_graph=True)
        grad_vector_product = sum(torch.sum(g * v) for g, v in zip(grad, vector))
        
        hvp = torch.autograd.grad(grad_vector_product, model.parameters(), retain_graph=True)
        return list(hvp)

class UnlearningEngine:
    """ì–¸ëŸ¬ë‹ ì—”ì§„ í´ë˜ìŠ¤ - ë™ì  ì§êµì„± ìŠ¤ì¼€ì¼ë§(DOS)"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
    
    def perform_unlearning(self, model: nn.Module, harmful_samples: List[Tuple], 
                          influence_scores: List[float], retain_samples: List[Tuple],
                          target_test_loader: DataLoader) -> float:
        """ë™ì  ì§êµì„± ìŠ¤ì¼€ì¼ë§(DOS) ì–¸ëŸ¬ë‹ ìˆ˜í–‰"""
        method = self.config.get('unlearning', 'method')
        
        if method == 'dos':
            return self._perform_dos_unlearning(model, harmful_samples, influence_scores, 
                                              retain_samples, target_test_loader)
        elif method == 'simple_dos':
            return self._perform_simple_dos_unlearning(model, harmful_samples, influence_scores)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ëŸ¬ë‹ ë°©ë²•: {method}")
    
    def _perform_dos_unlearning(self, model: nn.Module, harmful_samples: List[Tuple],
                              influence_scores: List[float], retain_samples: List[Tuple],
                              target_test_loader: DataLoader) -> float:
        """ë™ì  ì§êµì„± ìŠ¤ì¼€ì¼ë§(DOS) ì–¸ëŸ¬ë‹"""
        num_steps = self.config.get('unlearning', 'num_steps', 10)
        unlearn_lr = self.config.get('unlearning', 'learning_rate', 0.001)
        
        print(f"ğŸ”§ DOS ì–¸ëŸ¬ë‹ ìˆ˜í–‰ ì¤‘... (ì‚­ì œ: {len(harmful_samples)}ê°œ, ìœ ì§€: {len(retain_samples)}ê°œ)")
        
        model.train()
        
        # ì–¸ëŸ¬ë‹ ì „ ì„±ëŠ¥ ê¸°ë¡
        pre_unlearn_target_acc = self._evaluate_model(model, target_test_loader)
        
        # 1. ìœ í•´ì„± ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì •ê·œí™” (w_i = -I_up(z_i))
        harmful_weights = []
        for score in influence_scores:
            weight = max(-score, 0)  # ìŒìˆ˜ ì˜í–¥ë„ë§Œ ì‚¬ìš©
            harmful_weights.append(weight)
        
        total_weight = sum(harmful_weights)
        if total_weight > 0:
            normalized_weights = [w / total_weight for w in harmful_weights]
        else:
            normalized_weights = [1.0 / len(harmful_samples)] * len(harmful_samples)
        
        # 2. ìœ ì§€ ì„¸íŠ¸ì˜ í‰ê·  ê¸°ìš¸ê¸° ê³„ì‚°
        retain_gradients = []
        for data, target in retain_samples:
            data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
            
            model.zero_grad()
            output = model(data)
            loss = F.cross_entropy(output, target)
            
            grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)
            retain_gradients.append([g.clone() for g in grad])
        
        # í‰ê·  ìœ ì§€ ê¸°ìš¸ê¸°
        avg_retain_grad = []
        for i in range(len(retain_gradients[0])):
            param_grads = [rg[i] for rg in retain_gradients]
            avg_grad = torch.stack(param_grads).mean(dim=0)
            avg_retain_grad.append(avg_grad)
        
        # DOS ì–¸ëŸ¬ë‹ ìˆ˜í–‰
        unlearn_optimizer = optim.SGD(model.parameters(), lr=unlearn_lr)
        
        for step in range(num_steps):
            # 3. ê°€ì¤‘ì¹˜ ì ìš©ëœ ì‚­ì œ ê¸°ìš¸ê¸° ê³„ì‚° (g_f^weighted)
            weighted_forget_grad = None
            
            for (data, target), weight in zip(harmful_samples, normalized_weights):
                data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
                
                model.zero_grad()
                output = model(data)
                loss = F.cross_entropy(output, target)
                
                grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True)
                
                if weighted_forget_grad is None:
                    weighted_forget_grad = [weight * g for g in grad]
                else:
                    for i, g in enumerate(grad):
                        weighted_forget_grad[i] += weight * g
            
            # 4. ì§êµ ì–¸ëŸ¬ë‹: ìœ ì§€ ì§€ì‹ ë°©í–¥ ì„±ë¶„ ì œê±°
            if weighted_forget_grad is not None:
                dot_product = 0
                retain_norm_squared = 0
                
                for wfg, arg in zip(weighted_forget_grad, avg_retain_grad):
                    dot_product += torch.sum(wfg * arg).item()
                    retain_norm_squared += torch.sum(arg * arg).item()
                
                if retain_norm_squared > 1e-8:
                    projection_coeff = dot_product / retain_norm_squared
                else:
                    projection_coeff = 0
                
                # 5. ì§êµ ê¸°ìš¸ê¸°ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
                unlearn_optimizer.zero_grad()
                
                for param, wfg, arg in zip(model.parameters(), weighted_forget_grad, avg_retain_grad):
                    orthogonal_grad = wfg - projection_coeff * arg
                    param.grad = orthogonal_grad.clone()
                
                unlearn_optimizer.step()
        
        # ì–¸ëŸ¬ë‹ í›„ ì„±ëŠ¥ í™•ì¸
        post_unlearn_target_acc = self._evaluate_model(model, target_test_loader)
        performance_change = post_unlearn_target_acc - pre_unlearn_target_acc
        
        print(f"ğŸ“Š ì–¸ëŸ¬ë‹ ì™„ë£Œ: {pre_unlearn_target_acc:.2f}% â†’ {post_unlearn_target_acc:.2f}% ({performance_change:+.2f}%)")
        
        return performance_change
    
    def _perform_simple_dos_unlearning(self, model: nn.Module, harmful_samples: List[Tuple],
                                     influence_scores: List[float]) -> float:
        """ê°„ë‹¨í•œ DOS ì–¸ëŸ¬ë‹"""
        num_steps = self.config.get('unlearning', 'num_steps')
        unlearn_lr = self.config.get('unlearning', 'learning_rate')
        
        flush_print(f"ğŸ”§ ê°„ë‹¨í•œ DOS ì–¸ëŸ¬ë‹ ìˆ˜í–‰ ì¤‘... (ìŠ¤í…: {num_steps})")
        
        model.train()
        unlearn_optimizer = optim.SGD(model.parameters(), lr=unlearn_lr)
        
        for step in range(num_steps):
            total_loss = 0
            
            for data, target in harmful_samples:
                data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
                
                unlearn_optimizer.zero_grad()
                output = model(data)
                
                loss = F.cross_entropy(output, target)
                unlearn_loss = -0.05 * loss  # ìŒìˆ˜ ê°•ë„
                
                unlearn_loss.backward()
                unlearn_optimizer.step()
                
                total_loss += unlearn_loss.item()
            
            avg_loss = total_loss / len(harmful_samples)
            flush_print(f"   ìŠ¤í… {step+1}: ì–¸ëŸ¬ë‹ ì†ì‹¤ = {avg_loss:.4f}")
        
        flush_print("âœ… ê°„ë‹¨í•œ DOS ì–¸ëŸ¬ë‹ ì™„ë£Œ")
        return 0.0  # ì„±ëŠ¥ ë³€í™” ë°˜í™˜í•˜ì§€ ì•ŠìŒ
    
    def _evaluate_model(self, model: nn.Module, data_loader: DataLoader, max_batches: int = None) -> float:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (ì „ì²´ ë°ì´í„° í‰ê°€)"""
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(data_loader):
                if max_batches is not None and batch_idx >= max_batches:
                    break
                    
                data, target = data.to(device), target.to(device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = 100 * correct / total
        return accuracy

class ModelTrainer:
    """ëª¨ë¸ í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, config: SDAUConfig):
        self.config = config
    
    def train_source_model(self, model: nn.Module, source_train_loader: DataLoader,
                          source_test_loader: DataLoader, source_domain: str, dataset: str) -> float:
        """ì†ŒìŠ¤ ëª¨ë¸ í›ˆë ¨ ë˜ëŠ” ë¡œë”©"""
        # ì†ŒìŠ¤ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        source_models_dir = Path(self.config.get('paths', 'source_models_dir')) / dataset
        source_models_dir.mkdir(parents=True, exist_ok=True)
        source_model_path = source_models_dir / f"{source_domain}_source_model.pt"
        
        flush_print(f"\nğŸ” ì†ŒìŠ¤ ëª¨ë¸ í™•ì¸: {source_model_path}")
        
        # ê¸°ì¡´ ì†ŒìŠ¤ ëª¨ë¸ ë¡œë”© ì‹œë„
        if source_model_path.exists():
            try:
                flush_print(f"ğŸ“¥ ê¸°ì¡´ ì†ŒìŠ¤ ëª¨ë¸ ë¡œë”© ì¤‘...")
                checkpoint = torch.load(source_model_path, map_location=device)
                model.load_state_dict(checkpoint['model_state_dict'])
                
                source_acc = self._evaluate_model(model, source_test_loader)
                
                if source_acc > 50.0:
                    flush_print(f"âœ… ê¸°ì¡´ ì†ŒìŠ¤ ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
                    flush_print(f"   ğŸ“Š ì†ŒìŠ¤ ë„ë©”ì¸ ì„±ëŠ¥: {source_acc:.2f}%")
                    return source_acc
                else:
                    flush_print(f"âš ï¸ ê¸°ì¡´ ëª¨ë¸ ì„±ëŠ¥ì´ ë‚®ìŒ ({source_acc:.2f}%), ì¬í›ˆë ¨ í•„ìš”")
            except Exception as e:
                flush_print(f"âš ï¸ ê¸°ì¡´ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        
        # ìƒˆë¡œìš´ ì†ŒìŠ¤ ëª¨ë¸ í›ˆë ¨
        flush_print(f"\nğŸ‹ï¸ ì†ŒìŠ¤ ë„ë©”ì¸ í›ˆë ¨ ì‹œì‘...")
        
        model.train()
        learning_rate = self.config.get('training', 'learning_rate')
        weight_decay = self.config.get('training', 'weight_decay')
        
        optimizer = optim.Adam(model.parameters(), lr=learning_rate * 2, weight_decay=weight_decay)
        
        best_source_acc = 0.0
        best_source_state = None
        patience = 0
        max_patience = 30
        
        for epoch in range(100):  # ìµœëŒ€ 100 ì—í¬í¬
            total_loss = 0
            correct = 0
            total = 0
            
            for batch_idx, (data, target) in enumerate(source_train_loader):
                # OfficeHome í˜¸í™˜ì„±: targetì´ ì •ìˆ˜ì¸ ê²½ìš° í…ì„œë¡œ ë³€í™˜
                if isinstance(target, (list, tuple)):
                    target = torch.tensor(target)
                elif not torch.is_tensor(target):
                    target = torch.tensor([target] if isinstance(target, int) else target)
                
                data, target = data.to(device), target.to(device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = F.cross_entropy(output, target)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
            
            train_acc = 100 * correct / total
            source_acc = self._evaluate_model(model, source_test_loader)
            
            flush_print(f"   ì—í¬í¬ {epoch+1:2d}: í›ˆë ¨ {train_acc:5.2f}% | í…ŒìŠ¤íŠ¸ {source_acc:5.2f}%")
            
            if source_acc > best_source_acc:
                best_source_acc = source_acc
                best_source_state = copy.deepcopy(model.state_dict())
                patience = 0
                
                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                torch.save({
                    'model_state_dict': best_source_state,
                    'source_accuracy': best_source_acc,
                    'epoch': epoch + 1,
                    'config': self.config.config
                }, source_model_path)
                flush_print(f"      ğŸ’¾ ìµœê³  ì„±ëŠ¥ ì €ì¥ (ì„±ëŠ¥: {source_acc:.2f}%)")
            else:
                patience += 1
                
            if patience >= max_patience:
                flush_print(f"   â±ï¸ ì„±ëŠ¥ ê°œì„  ì—†ìŒ ({max_patience}ì—í¬í¬). ì¡°ê¸° ì¢…ë£Œ")
                break
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
        if best_source_state is not None:
            model.load_state_dict(best_source_state)
            flush_print(f"âœ… ì†ŒìŠ¤ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ìµœê³  ì„±ëŠ¥: {best_source_acc:.2f}%")
            return best_source_acc
        else:
            flush_print(f"âŒ ì†ŒìŠ¤ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
            return 0.0
    
    def train_with_target_samples(self, model: nn.Module, target_samples: List[Tuple], 
                                 num_epochs: int = 1) -> None:
        """íƒ€ê²Ÿ ìƒ˜í”Œë¡œ ì ì‘ í›ˆë ¨"""
        if not target_samples:
            return
            
        model.train()
        
        learning_rate = self.config.get('training', 'learning_rate')
        weight_decay = self.config.get('training', 'weight_decay')
        
        # ìƒ˜í”Œ ìˆ˜ì— ë”°ë¥¸ í•™ìŠµë¥  ì¡°ì • (ì•ˆì „í•œ í•™ìŠµë¥ ë¡œ ë³€ê²½)
        if len(target_samples) < 50:
            initial_lr = learning_rate * 0.5
            final_lr = learning_rate * 0.1
        else:
            initial_lr = learning_rate * 1.0
            final_lr = learning_rate * 0.2
        
        optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=weight_decay * 0.2)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=final_lr)
        
        # ë°°ì¹˜ ì²˜ë¦¬
        if len(target_samples) >= 24:
            batch_size = 8
            target_dataset = [(data, target) for data, target in target_samples]
            target_loader = DataLoader(target_dataset, batch_size=batch_size, shuffle=True)
            use_batches = True
        elif len(target_samples) >= 12:
            batch_size = 6
            target_dataset = [(data, target) for data, target in target_samples]
            target_loader = DataLoader(target_dataset, batch_size=batch_size, shuffle=True)
            use_batches = True
        else:
            use_batches = False
            repeat_factor = max(1, 8 // len(target_samples))
        
        for epoch in range(num_epochs):
            total_loss = 0
            batch_count = 0
            
            if use_batches:
                for data_batch, target_batch in target_loader:
                    data_batch, target_batch = data_batch.to(device), target_batch.to(device)
                    
                    optimizer.zero_grad()
                    output = model(data_batch)
                    loss = F.cross_entropy(output, target_batch)
                    
                    # L2 ì •ê·œí™”
                    if weight_decay > 0:
                        l2_reg = torch.tensor(0., requires_grad=True).to(device)
                        for param in model.parameters():
                            l2_reg = l2_reg + torch.norm(param, 2)
                        loss = loss + weight_decay * 0.1 * l2_reg
                    
                    loss.backward()
                    
                    # ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
                    clip_norm = self.config.get('training', 'gradient_clip_norm')
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_norm)
                    
                    optimizer.step()
                    
                    total_loss += loss.item()
                    batch_count += 1
            else:
                for repeat in range(repeat_factor):
                    for data, target in target_samples:
                        data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)
                        
                        optimizer.zero_grad()
                        output = model(data)
                        loss = F.cross_entropy(output, target)
                        
                        if weight_decay > 0:
                            l2_reg = torch.tensor(0., requires_grad=True).to(device)
                            for param in model.parameters():
                                l2_reg = l2_reg + torch.norm(param, 2)
                            loss = loss + weight_decay * 0.1 * l2_reg
                        
                        loss.backward()
                        
                        clip_norm = self.config.get('training', 'gradient_clip_norm')
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_norm)
                        
                        optimizer.step()
                        
                        total_loss += loss.item()
                        batch_count += 1
            
            scheduler.step()
    
    def _evaluate_model(self, model: nn.Module, data_loader: DataLoader, max_batches: int = 20) -> float:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(data_loader):
                if batch_idx >= max_batches:
                    break
                    
                data, target = data.to(device), target.to(device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = 100 * correct / total
        return accuracy

class SDAUAlgorithm:
    """í•µì‹¬ SDA-U ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ (ì™„ì „ ê°ì²´ì§€í–¥)"""
    
    def __init__(self, config_path: str = "config.json"):
        """SDA-U ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”"""
        self.config = SDAUConfig(config_path)
        self.model_manager = ModelManager(self.config)
        self.data_manager = DataManager(self.config)
        self.target_selector = TargetSampleSelector(self.config)
        self.influence_calculator = InfluenceCalculator(self.config)
        self.unlearning_engine = UnlearningEngine(self.config)
        self.model_trainer = ModelTrainer(self.config)
        
        # GPU ìµœì í™”
        if GPU_OPTIMIZED and self.config.get('gpu', 'auto_optimize'):
            setup_gpu_optimizations()
            flush_print(f"ğŸš€ GPU ìµœì í™” í™œì„±í™”: {get_gpu_info()['name']}")
        
        flush_print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {device}")
        flush_print(f"âš™ï¸ ì„¤ì • ë¡œë”© ì™„ë£Œ: {self.config.config_path}")
        
    def run_experiment(self, dataset: str, source_domain: str, target_domain: str) -> ExperimentResults:
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        flush_print("\n" + "="*80)
        flush_print("ğŸ¯ ì™„ì „ ê°ì²´ì§€í–¥ SDA-U ì•Œê³ ë¦¬ì¦˜ ì‹œì‘!")
        flush_print("="*80)
        flush_print(f"ğŸ“Š ë°ì´í„°ì…‹: {dataset}")
        flush_print(f"ğŸ  ì†ŒìŠ¤ ë„ë©”ì¸: {source_domain}")
        flush_print(f"ğŸ¯ íƒ€ê²Ÿ ë„ë©”ì¸: {target_domain}")
        
        # 1. ë°ì´í„° ë¡œë”©
        batch_size = self.config.get('training', 'batch_size')
        source_train_loader, source_test_loader, target_train_loader, target_test_loader, num_classes = \
            self.data_manager.load_dataset(dataset, source_domain, target_domain, batch_size)
        
        flush_print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ (í´ë˜ìŠ¤ ìˆ˜: {num_classes})")
        
        # 2. ëª¨ë¸ ìƒì„± ë° ì†ŒìŠ¤ ëª¨ë¸ í›ˆë ¨
        model = self.model_manager.create_model(num_classes)
        flush_print(f"ğŸ¤– ëª¨ë¸: {self.config.get('model', 'architecture')} (íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,})")
        
        source_accuracy = self.model_trainer.train_source_model(
            model, source_train_loader, source_test_loader, source_domain, dataset)
        
        # 3. í•µì‹¬ SDA-U ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
        results = self._core_sda_u_algorithm(
            model, source_train_loader, target_train_loader,
            target_test_loader, source_test_loader, num_classes,
            dataset, source_domain, target_domain
        )
        
        return results
    
    def _core_sda_u_algorithm(self, model: nn.Module, source_train_loader: DataLoader,
                             target_train_loader: DataLoader, target_test_loader: DataLoader,
                             source_test_loader: DataLoader, num_classes: int,
                             dataset: str, source_domain: str, target_domain: str) -> ExperimentResults:
        """í•µì‹¬ SDA-U ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰"""
        
        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì €ì¥ìš©
        performance_history = {
            'epoch': [],
            'target_acc': [],
            'source_acc': [],
            'phase': [],
            'unlearning_count': [],
            'is_best': []
        }
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
        model_save_dir = Path(self.config.get('paths', 'model_save_dir')) / f"{source_domain}2{target_domain}"
        model_save_dir.mkdir(parents=True, exist_ok=True)
        
        best_model_path = model_save_dir / "best_model.pt"
        final_model_path = model_save_dir / "final_model.pt"
        performance_log_path = model_save_dir / "performance_history.json"
        
        flush_print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_save_dir}")
        
        # 1. íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„
        target_samples = self.target_selector.select_samples(model, target_train_loader, num_classes)
        flush_print(f"âœ… ì„ ë³„ëœ íƒ€ê²Ÿ ìƒ˜í”Œ: {len(target_samples)}ê°œ")
        
        # ì´ˆê¸° ì„±ëŠ¥ ì¸¡ì •
        initial_target_acc = self._evaluate_model(model, target_test_loader)
        initial_source_acc = self._evaluate_model(model, source_test_loader)
        
        flush_print(f"\nğŸ“Š ì´ˆê¸° ì„±ëŠ¥:")
        flush_print(f"   ğŸ¯ íƒ€ê²Ÿ: {initial_target_acc:.2f}%")
        flush_print(f"   ğŸ  ì†ŒìŠ¤: {initial_source_acc:.2f}%")
        
        # ì´ˆê¸° ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        performance_history['epoch'].append(0)
        performance_history['target_acc'].append(initial_target_acc)
        performance_history['source_acc'].append(initial_source_acc)
        performance_history['phase'].append('initial')
        performance_history['unlearning_count'].append(0)
        performance_history['is_best'].append(True)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì¶”ì 
        best_model_state = copy.deepcopy(model.state_dict())
        best_target_acc = initial_target_acc
        best_epoch = 0
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        self.model_manager.save_model(model, str(best_model_path), {
            'epoch': 0,
            'target_accuracy': best_target_acc,
            'source_accuracy': initial_source_acc,
            'dataset': dataset,
            'source_domain': source_domain,
            'target_domain': target_domain
        })
        
        # ì„¤ì •ê°’ ì½ê¸°
        max_epochs = self.config.get('training', 'max_epochs')
        patience_limit = self.config.get('training', 'patience')
        epoch_chunk_size = self.config.get('training', 'epoch_chunk_size')
        
        # ì„±ëŠ¥ ì •ì²´ ì¶”ì 
        stagnation_count = 0
        unlearning_count = 0
        
        print(f"\nğŸ‹ï¸ íƒ€ê²Ÿ ë„ë©”ì¸ ì ì‘ í›ˆë ¨ ì‹œì‘ ({max_epochs}ì—í¬í¬, {patience_limit}ì—í¬í¬ ì •ì²´ ì‹œ ì–¸ëŸ¬ë‹)")
        
        epoch = 0
        while epoch < max_epochs:
            # epoch_chunk_size ì—í¬í¬ì”© í›ˆë ¨
            for sub_epoch in range(epoch_chunk_size):
                if epoch + sub_epoch >= max_epochs:
                    break
                    
                current_epoch = epoch + sub_epoch + 1
                
                # 1ì—í¬í¬ í›ˆë ¨
                self.model_trainer.train_with_target_samples(model, target_samples, num_epochs=1)
                
                # ì„±ëŠ¥ ì¸¡ì • (ì„¤ì •ê°’ì— ë”°ë¼)
                log_interval = self.config.get('performance', 'log_interval')
                if current_epoch % log_interval == 0 or sub_epoch == epoch_chunk_size - 1:
                    current_target_acc = self._evaluate_model(model, target_test_loader)
                    current_source_acc = self._evaluate_model(model, source_test_loader)
                    
                    improvement = current_target_acc - best_target_acc
                    is_best = current_target_acc > best_target_acc
                    
                    print(f"ì—í¬í¬ {current_epoch:3d}: íƒ€ê²Ÿ {current_target_acc:5.2f}% | ì†ŒìŠ¤ {current_source_acc:5.2f}% {'ğŸ†' if is_best else ''}")
                    
                    # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                    performance_history['epoch'].append(current_epoch)
                    performance_history['target_acc'].append(current_target_acc)
                    performance_history['source_acc'].append(current_source_acc)
                    performance_history['phase'].append('training')
                    performance_history['unlearning_count'].append(unlearning_count)
                    performance_history['is_best'].append(is_best)
                    
                    # ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                    if is_best:
                        best_target_acc = current_target_acc
                        best_epoch = current_epoch
                        best_model_state = copy.deepcopy(model.state_dict())
                        stagnation_count = 0
                        
                        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                        self.model_manager.save_model(model, str(best_model_path), {
                            'epoch': current_epoch,
                            'target_accuracy': best_target_acc,
                            'source_accuracy': current_source_acc,
                            'unlearning_count': unlearning_count
                        })
            
            epoch += epoch_chunk_size
            
            # epoch_chunk_size ë‹¨ìœ„ë¡œ ì •ì²´ í™•ì¸
            last_target_acc = performance_history['target_acc'][-1] if performance_history['target_acc'] else 0
            if last_target_acc <= best_target_acc:
                stagnation_count += epoch_chunk_size
                
                # patience_limit ì´ìƒ ì •ì²´ ì‹œ ì–¸ëŸ¬ë‹
                if stagnation_count >= patience_limit and epoch < max_epochs:
                    print(f"\nğŸ”§ ì–¸ëŸ¬ë‹ ìˆ˜í–‰ #{unlearning_count+1} (ì •ì²´: {stagnation_count}ì—í¬í¬)")
                    
                    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
                    model.load_state_dict(best_model_state)
                    
                    # ì˜í–¥ë„ ê³„ì‚° ë° ì–¸ëŸ¬ë‹ ìˆ˜í–‰
                    performance_change = self._perform_unlearning_cycle(
                        model, source_train_loader, target_samples, target_test_loader)
                    
                    unlearning_count += 1
                    
                    # ì–¸ëŸ¬ë‹ í›„ ì„±ëŠ¥ ì¸¡ì •
                    after_unlearn_target_acc = self._evaluate_model(model, target_test_loader)
                    after_unlearn_source_acc = self._evaluate_model(model, source_test_loader)
                    
                    # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                    performance_history['epoch'].append(epoch)
                    performance_history['target_acc'].append(after_unlearn_target_acc)
                    performance_history['source_acc'].append(after_unlearn_source_acc)
                    performance_history['phase'].append(f'unlearning_{unlearning_count}')
                    performance_history['unlearning_count'].append(unlearning_count)
                    performance_history['is_best'].append(after_unlearn_target_acc > best_target_acc)
                    
                    # ì–¸ëŸ¬ë‹ìœ¼ë¡œ ì„±ëŠ¥ì´ ê°œì„ ë˜ë©´ ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                    if after_unlearn_target_acc > best_target_acc:
                        print(f"ğŸ† ì–¸ëŸ¬ë‹ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! {best_target_acc:.2f}% â†’ {after_unlearn_target_acc:.2f}%")
                        best_target_acc = after_unlearn_target_acc
                        best_epoch = epoch
                        best_model_state = copy.deepcopy(model.state_dict())
                        
                        self.model_manager.save_model(model, str(best_model_path), {
                            'epoch': epoch,
                            'target_accuracy': best_target_acc,
                            'source_accuracy': after_unlearn_source_acc,
                            'unlearning_count': unlearning_count,
                            'phase': f'unlearning_{unlearning_count}'
                        })
                    
                    stagnation_count = 0  # ì •ì²´ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            else:
                stagnation_count = 0  # ì„±ëŠ¥ì´ ê°œì„ ë˜ë©´ ì •ì²´ ì¹´ìš´íŠ¸ ë¦¬ì…‹
            
            # ì¤‘ê°„ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì €ì¥
            if epoch % 50 == 0:
                with open(performance_log_path, 'w', encoding='utf-8') as f:
                    json.dump(performance_history, f, indent=2, ensure_ascii=False)
        
        # ìµœì¢… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì›
        flush_print(f"\nğŸ† ìµœì¢… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ë³µì› (ì—í¬í¬ {best_epoch}, ì„±ëŠ¥: {best_target_acc:.2f}%)")
        model.load_state_dict(best_model_state)
        
        # ìµœì¢… ì„±ëŠ¥ ì¸¡ì •
        final_target_acc = self._evaluate_model(model, target_test_loader)
        final_source_acc = self._evaluate_model(model, source_test_loader)
        
        # ìµœì¢… ì„±ëŠ¥ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        performance_history['epoch'].append('final')
        performance_history['target_acc'].append(final_target_acc)
        performance_history['source_acc'].append(final_source_acc)
        performance_history['phase'].append('final')
        performance_history['unlearning_count'].append(unlearning_count)
        performance_history['is_best'].append(final_target_acc >= best_target_acc)
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        self.model_manager.save_model(model, str(final_model_path), {
            'epoch': 'final',
            'target_accuracy': final_target_acc,
            'source_accuracy': final_source_acc,
            'best_target_accuracy': best_target_acc,
            'best_epoch': best_epoch,
            'unlearning_count': unlearning_count,
            'performance_history': performance_history
        })
        
        # ìµœì¢… ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì €ì¥
        with open(performance_log_path, 'w', encoding='utf-8') as f:
            json.dump(performance_history, f, indent=2, ensure_ascii=False)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print("ğŸ¯ SDA-U ì•Œê³ ë¦¬ì¦˜ ì™„ë£Œ!")
        print(f"{'='*60}")
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"   íƒ€ê²Ÿ: {initial_target_acc:.2f}% â†’ {final_target_acc:.2f}% ({final_target_acc-initial_target_acc:+.2f}%)")
        print(f"   ì†ŒìŠ¤: {initial_source_acc:.2f}% â†’ {final_source_acc:.2f}%")
        print(f"   ğŸ† ìµœê³ : {best_target_acc:.2f}% (ì—í¬í¬ {best_epoch})")
        print(f"   ì–¸ëŸ¬ë‹: {unlearning_count}íšŒ, ì—í¬í¬: {min(epoch, max_epochs)}")
        
        return ExperimentResults(
            initial_target_acc=initial_target_acc,
            final_target_acc=final_target_acc,
            best_target_acc=best_target_acc,
            best_epoch=best_epoch,
            improvement=final_target_acc - initial_target_acc,
            best_improvement=best_target_acc - initial_target_acc,
            unlearning_count=unlearning_count,
            total_epochs=min(epoch, max_epochs),
            performance_history=performance_history,
            model_paths={
                'best_model': str(best_model_path),
                'final_model': str(final_model_path),
                'performance_log': str(performance_log_path)
            }
        )
    
    def _perform_unlearning_cycle(self, model: nn.Module, source_train_loader: DataLoader,
                                 target_samples: List[Tuple], target_test_loader: DataLoader) -> float:
        """ì–¸ëŸ¬ë‹ ì‚¬ì´í´ ìˆ˜í–‰"""
        # ì˜í–¥ë„ ê³„ì‚°
        flush_print(f"ğŸ§® ì˜í–¥ë„ ê³„ì‚° ì¤‘...")
        source_samples, influence_scores = self.influence_calculator.compute_influence_scores(
            model, source_train_loader, target_samples)
        
        # ìœ í•´í•œ ìƒ˜í”Œ ì„ ë³„ (ìŒìˆ˜ ì˜í–¥ë„ë§Œ)
        harmful_indices = [i for i, score in enumerate(influence_scores) if score < 0]
        harmful_samples = [source_samples[i] for i in harmful_indices]
        harmful_influence_scores = [influence_scores[i] for i in harmful_indices]
        
        # ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ
        max_influence_samples = self.config.get('influence_calculation', 'max_influence_samples')
        if len(harmful_samples) > max_influence_samples:
            sorted_pairs = sorted(zip(harmful_samples, harmful_influence_scores), 
                                key=lambda x: x[1])  # ìŒìˆ˜ê°€ ì‘ì„ìˆ˜ë¡ ë” ìœ í•´
            harmful_samples = [pair[0] for pair in sorted_pairs[:max_influence_samples]]
            harmful_influence_scores = [pair[1] for pair in sorted_pairs[:max_influence_samples]]
        
        flush_print(f"ğŸ” ìœ í•´ ìƒ˜í”Œ ë°œê²¬: {len(harmful_samples)}ê°œ (ì „ì²´ {len(source_samples)}ê°œ ì¤‘)")
        
        if len(harmful_samples) > 0:
            # ì–¸ëŸ¬ë‹ ìˆ˜í–‰
            performance_change = self.unlearning_engine.perform_unlearning(
                model, harmful_samples, harmful_influence_scores, target_samples, target_test_loader)
            
            flush_print(f"ğŸ“Š ì–¸ëŸ¬ë‹ ì„±ëŠ¥ ë³€í™”: {performance_change:+.2f}%")
            return performance_change
        else:
            flush_print("âš ï¸ ìœ í•´í•œ ì†ŒìŠ¤ ìƒ˜í”Œì´ ë°œê²¬ë˜ì§€ ì•ŠìŒ. ì–¸ëŸ¬ë‹ ê±´ë„ˆë›°ê¸°.")
            return 0.0
    
    def _evaluate_model(self, model: nn.Module, data_loader: DataLoader) -> float:
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        model.eval()
        correct = 0
        total = 0
        
        max_batches = self.config.get('performance', 'evaluation_batch_limit')
        
        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(data_loader):
                if batch_idx >= max_batches:
                    break
                    
                data, target = data.to(device), target.to(device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = 100 * correct / total
        return accuracy

def main():
    """ë©”ì¸ í•¨ìˆ˜ (ì™„ì „ ê°ì²´ì§€í–¥)"""
    parser = argparse.ArgumentParser(description='ì™„ì „ ê°ì²´ì§€í–¥ SDA-U ì•Œê³ ë¦¬ì¦˜')
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument('--dataset', type=str, required=True, choices=['Office31', 'OfficeHome'])
    parser.add_argument('--source_domain', type=str, required=True)
    parser.add_argument('--target_domain', type=str, required=True)
    
    # ì„ íƒì  ì¸ì
    parser.add_argument('--config', type=str, default='config.json', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--results_file', type=str, default='results.json', help='ê²°ê³¼ íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    flush_print("ğŸ¯ ì™„ì „ ê°ì²´ì§€í–¥ SDA-U ì•Œê³ ë¦¬ì¦˜ ì‹œì‘!")
    flush_print(f"ğŸ“Š ì‹¤í—˜ ì„¤ì •:")
    flush_print(f"   ë°ì´í„°ì…‹: {args.dataset}")
    flush_print(f"   ì†ŒìŠ¤ ë„ë©”ì¸: {args.source_domain}")
    flush_print(f"   íƒ€ê²Ÿ ë„ë©”ì¸: {args.target_domain}")
    flush_print(f"   ì„¤ì • íŒŒì¼: {args.config}")
    
    try:
        # SDA-U ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™” ë° ì‹¤í–‰
        sda_u = SDAUAlgorithm(config_path=args.config)
        results = sda_u.run_experiment(args.dataset, args.source_domain, args.target_domain)
        
        # ê²°ê³¼ ì €ì¥
        results_dict = {
            'dataset': args.dataset,
            'source_domain': args.source_domain,
            'target_domain': args.target_domain,
            'initial_target_acc': results.initial_target_acc,
            'final_target_acc': results.final_target_acc,
            'best_target_acc': results.best_target_acc,
            'best_epoch': results.best_epoch,
            'improvement': results.improvement,
            'best_improvement': results.best_improvement,
            'unlearning_count': results.unlearning_count,
            'total_epochs': results.total_epochs,
            'model_paths': results.model_paths,
            'timestamp': time.time()
        }
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        results_dir = Path(sda_u.config.get('paths', 'results_dir'))
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        results_path = results_dir / args.results_file
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, indent=2, ensure_ascii=False)
        
        flush_print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
        flush_print(f"   ğŸ“„ ê²°ê³¼ íŒŒì¼: {results_path}")
        flush_print(f"   ğŸ† ìµœê³  ëª¨ë¸: {results.model_paths['best_model']}")
        flush_print(f"   ğŸ“Š ì„±ëŠ¥ ë¡œê·¸: {results.model_paths['performance_log']}")
        
        flush_print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ! ìµœê³  ì„±ëŠ¥: {results.best_target_acc:.2f}%")
        
    except Exception as e:
        flush_print(f"âŒ ì‹¤í—˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 