# config.py - SDA-U í”„ë ˆì„ì›Œí¬ ì„¤ì • íŒŒì¼

# ============================================
# ğŸ¯ ì•„í‚¤í…ì²˜ ì„ íƒ (ì›í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!)
# ============================================
# ì˜µì…˜:
# - 'resnet18': ResNet-18 (ë¹ ë¦„, 11M íŒŒë¼ë¯¸í„°)
# - 'resnet50': ResNet-50 (ê· í˜•, 25M íŒŒë¼ë¯¸í„°) 
# - 'vit_b_16': Vision Transformer Base (ê³ ì„±ëŠ¥, 86M íŒŒë¼ë¯¸í„°)
# - 'vit_l_16': Vision Transformer Large (ìµœê³ ì„±ëŠ¥, 304M íŒŒë¼ë¯¸í„°, GPU ë©”ëª¨ë¦¬ ë§ì´ í•„ìš”)
# - 'custom_cnn': ì»¤ìŠ¤í…€ CNN (ê°€ë²¼ì›€, 0.1M íŒŒë¼ë¯¸í„°)

ARCHITECTURE = 'resnet50'  # ğŸ‘ˆ ì—¬ê¸°ë¥¼ ë³€ê²½í•˜ì„¸ìš”!

# ============================================
# ğŸ“Š ë°ì´í„°ì…‹ ì„ íƒ (ìƒˆë¡œ ì¶”ê°€!)
# ============================================
# ì†ŒìŠ¤ â†’ íƒ€ê²Ÿ ë„ë©”ì¸ ì ì‘ ìŒ ì„ íƒ
# ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹: MNIST, SVHN, CIFAR10, CIFAR100, FashionMNIST, KMNIST, EMNIST
# Office-31: Office31_Amazon, Office31_Webcam, Office31_DSLR

SOURCE_DATASET = 'Office31_Amazon'     # ì†ŒìŠ¤ ë„ë©”ì¸ (ê³ í’ˆì§ˆ ì œí’ˆ ì´ë¯¸ì§€)
TARGET_DATASET = 'Office31_Webcam'    # íƒ€ê²Ÿ ë„ë©”ì¸ (ì €í’ˆì§ˆ ì›¹ìº  ì´ë¯¸ì§€)

# ì¶”ì²œ ì¡°í•©ë“¤:
# - SVHN â†’ MNIST: ì»¬ëŸ¬ ê±°ë¦¬ë²ˆí˜¸ â†’ í‘ë°± ì†ê¸€ì”¨ (ê¸°ë³¸)
# - CIFAR10 â†’ FashionMNIST: ì¼ë°˜ì‚¬ë¬¼ â†’ íŒ¨ì…˜ì•„ì´í…œ
# - MNIST â†’ KMNIST: ì•„ë¼ë¹„ì•„ ìˆ«ì â†’ ì¼ë³¸ ë¬¸ì
# - CIFAR10 â†’ CIFAR100: 10í´ë˜ìŠ¤ â†’ 100í´ë˜ìŠ¤
# - Office31_Amazon â†’ Office31_Webcam: ê³ í’ˆì§ˆ â†’ ì €í’ˆì§ˆ (ë„ë©”ì¸ ì ì‘ ë²¤ì¹˜ë§ˆí¬!)
# - Office31_Amazon â†’ Office31_DSLR: ì¸ê³µì  â†’ ìì—°ìŠ¤ëŸ¬ìš´

# ============================================
# ğŸ”§ í›ˆë ¨ ì„¤ì •
# ============================================
BATCH_SIZE = 64           # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)
NUM_EPOCHS = 3            # í›ˆë ¨ ì—í¬í¬ ìˆ˜
LEARNING_RATE = 1e-3      # í•™ìŠµë¥ 

# ============================================
# ğŸ¯ SDA-U ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
# ============================================
TARGET_SUBSET_SIZE = 1000    # íƒ€ê²Ÿ ì„œë¸Œì…‹ í¬ê¸°
NUM_UNLEARN_STEPS = 5        # ì–¸ëŸ¬ë‹ ìŠ¤í… ìˆ˜
INFLUENCE_SAMPLES = 300      # ì˜í–¥ë„ ê³„ì‚° ìƒ˜í”Œ ìˆ˜
ADAPTATION_EPOCHS = 100      # íƒ€ê²Ÿ ë„ë©”ì¸ ì ì‘ í›ˆë ¨ ì—í¬í¬ ìˆ˜ (ì¶©ë¶„í•œ ì ì‘ì„ ìœ„í•´)
MAX_UNLEARN_SAMPLES = 200    # ì–¸ëŸ¬ë‹í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (ì‹¤í—˜ìš©ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥)

# í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ íŒŒë¼ë¯¸í„°
LAMBDA_U = 0.6              # ì˜í–¥ë„ ê°€ì¤‘ì¹˜
BETA = 0.1                  # ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜

# ============================================
# ğŸ’¾ ì €ì¥ ì„¤ì •
# ============================================
SAVE_MODELS = True          # ëª¨ë¸ ì €ì¥ ì—¬ë¶€
SAVE_RESULTS = True         # ê²°ê³¼ ì €ì¥ ì—¬ë¶€

# ============================================
# ğŸš€ ì‹¤í–‰ ëª¨ë“œ ì„¤ì •
# ============================================
QUICK_TEST = False          # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (True: 30ë°°ì¹˜ë§Œ, False: ì „ì²´ ë°ì´í„°)

# ============================================
# ğŸš€ GPU ìµœì í™” ì„¤ì •
# ============================================
def get_config():
    """ì„¤ì •ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    import torch
    
    # GPU ê°ì§€ ë° ìµœì í™”
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        # A100 ìµœì í™”
        if "A100" in gpu_name:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            print("ğŸš€ A100 ìµœì í™” í™œì„±í™”!")
            
            # A100ìš© ê³ ì„±ëŠ¥ ì„¤ì •
            if gpu_memory >= 70:
                return {
                    'architecture': 'vit_l_16',  # A100ì—ì„œëŠ” ViT Large ì¶”ì²œ
                    'batch_size': 128,
                    'num_epochs': 5,
                    'target_subset_size': 2000,
                    'num_unlearn_steps': 10,
                    'source_dataset': SOURCE_DATASET,
                    'target_dataset': TARGET_DATASET,
                    'gpu_name': gpu_name,
                    'gpu_memory': f"{gpu_memory:.1f}GB"
                }
    
    # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
    return {
        'architecture': ARCHITECTURE,
        'batch_size': BATCH_SIZE,
        'num_epochs': NUM_EPOCHS,
        'learning_rate': LEARNING_RATE,
        'target_subset_size': TARGET_SUBSET_SIZE,
        'num_unlearn_steps': NUM_UNLEARN_STEPS,
        'influence_samples': INFLUENCE_SAMPLES,
        'adaptation_epochs': ADAPTATION_EPOCHS,
        'max_unlearn_samples': MAX_UNLEARN_SAMPLES,
        'lambda_u': LAMBDA_U,
        'beta': BETA,
        'save_models': SAVE_MODELS,
        'save_results': SAVE_RESULTS,
        'quick_test': QUICK_TEST,
        'source_dataset': SOURCE_DATASET,
        'target_dataset': TARGET_DATASET,
        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'
    }

if __name__ == "__main__":
    # ì„¤ì • í…ŒìŠ¤íŠ¸
    config = get_config()
    print("ğŸ”§ í˜„ì¬ ì„¤ì •:")
    for key, value in config.items():
        print(f"   {key}: {value}")
        
    # ë°ì´í„°ì…‹ ì •ë³´ í‘œì‹œ
    from dataset_manager import DatasetManager
    manager = DatasetManager()
    
    print(f"\nğŸ“Š ì„ íƒëœ ë„ë©”ì¸ ì ì‘:")
    source_info = manager.get_dataset_info(SOURCE_DATASET)
    target_info = manager.get_dataset_info(TARGET_DATASET)
    
    if source_info and target_info:
        print(f"   ğŸ“¤ ì†ŒìŠ¤: {SOURCE_DATASET} - {source_info['description']}")
        print(f"   ğŸ“¥ íƒ€ê²Ÿ: {TARGET_DATASET} - {target_info['description']}")
    else:
        print(f"   âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.") 