"""
ðŸ”§ CIFAR10 â†” CIFAR100 í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ í•´ê²° ìœ í‹¸ë¦¬í‹°
CUDA ì˜¤ë¥˜ 'Assertion `t >= 0 && t < n_classes` failed' í•´ê²°ì„ ìœ„í•œ ë„êµ¬
"""

import os
import sys
import json
from pathlib import Path

def analyze_cifar_mismatch():
    """CIFAR ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ ë¬¸ì œ ë¶„ì„"""
    
    print("ðŸ” CIFAR10 â†” CIFAR100 í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ ë¶„ì„")
    print("="*60)
    
    datasets = {
        'CIFAR10': {
            'classes': 10,
            'labels': list(range(10)),
            'categories': ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                          'dog', 'frog', 'horse', 'ship', 'truck']
        },
        'CIFAR100': {
            'classes': 100,
            'labels': list(range(100)),
            'categories': f'100ê°œ ì„¸ë¶„í™”ëœ ì¹´í…Œê³ ë¦¬'
        }
    }
    
    print(f"ðŸ“Š CIFAR10:  {datasets['CIFAR10']['classes']}ê°œ í´ëž˜ìŠ¤ (ë¼ë²¨: 0-{datasets['CIFAR10']['classes']-1})")
    print(f"ðŸ“Š CIFAR100: {datasets['CIFAR100']['classes']}ê°œ í´ëž˜ìŠ¤ (ë¼ë²¨: 0-{datasets['CIFAR100']['classes']-1})")
    
    print(f"\nâŒ ë¬¸ì œ ìƒí™©:")
    print(f"   1. CIFAR10ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸: 10ê°œ í´ëž˜ìŠ¤ë§Œ ì²˜ë¦¬ ê°€ëŠ¥")
    print(f"   2. CIFAR100 íƒ€ê²Ÿ ë°ì´í„°: 0-99 ë¼ë²¨ í¬í•¨")
    print(f"   3. ì˜í–¥ë„ ê³„ì‚° ì‹œ: ë¼ë²¨ 10-99ê°€ ëª¨ë¸ í´ëž˜ìŠ¤ ìˆ˜(10)ë¥¼ ì´ˆê³¼")
    
    return datasets

def create_cifar_safe_config():
    """CIFAR ì•ˆì „ ì„¤ì • ìƒì„±"""
    
    print("\nðŸ”§ CIFAR ì•ˆì „ ì„¤ì • ìƒì„± ì¤‘...")
    
    # í•´ê²° ë°©ë²• 1: ê³µí†µ í´ëž˜ìŠ¤ ìˆ˜ ì‚¬ìš© (ìƒìœ„ í˜¸í™˜)
    safe_configs = {
        'method1_common_classes': {
            'description': 'ê³µí†µ í´ëž˜ìŠ¤ ìˆ˜ ì‚¬ìš© (CIFAR100 ê¸°ì¤€)',
            'num_classes': 100,  # CIFAR100 ê¸°ì¤€ìœ¼ë¡œ í†µì¼
            'label_mapping': 'expand_cifar10_to_100',
            'batch_size': 64,    # ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
            'influence_samples': 100,  # ìƒ˜í”Œ ìˆ˜ ê°ì†Œ
        },
        
        'method2_label_clipping': {
            'description': 'ë¼ë²¨ í´ë¦¬í•‘ ì‚¬ìš© (CIFAR10 ê¸°ì¤€)',
            'num_classes': 10,   # CIFAR10 ê¸°ì¤€ìœ¼ë¡œ í†µì¼
            'label_mapping': 'clip_cifar100_to_10',
            'batch_size': 64,
            'influence_samples': 100,
        },
        
        'method3_separate_models': {
            'description': 'ë°ì´í„°ì…‹ë³„ ë³„ë„ ëª¨ë¸ ì‚¬ìš©',
            'strategy': 'separate_experiments',
            'cifar10_classes': 10,
            'cifar100_classes': 100,
            'batch_size': 64,
            'influence_samples': 100,
        }
    }
    
    print("âœ… CIFAR ì•ˆì „ ì„¤ì • 3ê°€ì§€ ë°©ë²• ìƒì„± ì™„ë£Œ")
    return safe_configs

def generate_cifar_experiment_config(method='method2_label_clipping'):
    """CIFAR ì‹¤í—˜ìš© ì•ˆì „ config.py ìƒì„±"""
    
    print(f"\nâš™ï¸ CIFAR ì•ˆì „ ì‹¤í—˜ ì„¤ì • ìƒì„± ì¤‘ (ë°©ë²•: {method})...")
    
    configs = create_cifar_safe_config()
    selected_config = configs[method]
    
    if method == 'method2_label_clipping':
        # ë¼ë²¨ í´ë¦¬í•‘ ë°©ë²• (ê¶Œìž¥)
        config_content = f'''# config.py - CIFAR10â†’CIFAR100 ì•ˆì „ ì‹¤í—˜ìš© ì„¤ì •

# ============================================
# ðŸ”§ CIFAR í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ í•´ê²° (ë¼ë²¨ í´ë¦¬í•‘ ë°©ë²•)
# ============================================
ARCHITECTURE = 'resnet18'
BATCH_SIZE = 64           # ì•ˆì „í•œ ë°°ì¹˜ í¬ê¸°
NUM_EPOCHS = 20           # CIFARì— ì í•©í•œ ì—í¬í¬
LEARNING_RATE = 1e-3

# ðŸš¨ í´ëž˜ìŠ¤ ìˆ˜ í†µì¼ (CIFAR10 ê¸°ì¤€)
NUM_CLASSES = 10          # CIFAR10 ê¸°ì¤€ìœ¼ë¡œ ê³ ì •
LABEL_CLIPPING = True     # CIFAR100 ë¼ë²¨ì„ 0-9ë¡œ í´ë¦¬í•‘

# ë°ì´í„°ì…‹ ì„¤ì •
SOURCE_DATASET = 'CIFAR10'
TARGET_DATASET = 'CIFAR100'

# SDA-U ì•Œê³ ë¦¬ì¦˜ ì„¤ì • (ì•ˆì „ ëª¨ë“œ)
TARGET_SUBSET_SIZE = 300     # íƒ€ê²Ÿ ìƒ˜í”Œ ìˆ˜ ê°ì†Œ
NUM_UNLEARN_STEPS = 5        # ì–¸ëŸ¬ë‹ ìŠ¤í… ê°ì†Œ
INFLUENCE_SAMPLES = 100      # ì˜í–¥ë„ ìƒ˜í”Œ ìˆ˜ ëŒ€í­ ê°ì†Œ (200â†’100)
ADAPTATION_EPOCHS = 8        # ì ì‘ í›ˆë ¨ ì—í¬í¬
MAX_UNLEARN_SAMPLES = 50     # ìµœëŒ€ ì–¸ëŸ¬ë‹ ìƒ˜í”Œ ê°ì†Œ

# ðŸ”§ ì•ˆì „ ìž¥ì¹˜ ì„¤ì •
VALIDATE_LABELS = True       # ë¼ë²¨ ë²”ìœ„ ê²€ì¦ í™œì„±í™”
SKIP_INVALID_LABELS = True   # ìž˜ëª»ëœ ë¼ë²¨ ê±´ë„ˆë›°ê¸°
MAX_LABEL_VALUE = 9          # ìµœëŒ€ ë¼ë²¨ ê°’ (CIFAR10 ê¸°ì¤€)

# í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ íŒŒë¼ë¯¸í„°
LAMBDA_U = 0.6
BETA = 0.1

# ì €ìž¥ ì„¤ì •
SAVE_MODELS = True
SAVE_RESULTS = True
QUICK_TEST = False

def get_config():
    """ì„¤ì •ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (CIFAR ì•ˆì „ ëª¨ë“œ)"""
    import torch
    
    return {{
        'architecture': ARCHITECTURE,
        'batch_size': BATCH_SIZE,
        'num_epochs': NUM_EPOCHS,
        'learning_rate': LEARNING_RATE,
        'num_classes': NUM_CLASSES,
        'target_subset_size': TARGET_SUBSET_SIZE,
        'num_unlearn_steps': NUM_UNLEARN_STEPS,
        'influence_samples': INFLUENCE_SAMPLES,
        'adaptation_epochs': ADAPTATION_EPOCHS,
        'max_unlearn_samples': MAX_UNLEARN_SAMPLES,
        'validate_labels': VALIDATE_LABELS,
        'skip_invalid_labels': SKIP_INVALID_LABELS,
        'max_label_value': MAX_LABEL_VALUE,
        'label_clipping': LABEL_CLIPPING,
        'lambda_u': LAMBDA_U,
        'beta': BETA,
        'save_models': SAVE_MODELS,
        'save_results': SAVE_RESULTS,
        'quick_test': QUICK_TEST,
        'source_dataset': SOURCE_DATASET,
        'target_dataset': TARGET_DATASET,
        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'
    }}
'''
        
        # config.py íŒŒì¼ ìƒì„±
        with open('config_cifar_safe.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"âœ… ì•ˆì „í•œ CIFAR ì„¤ì • íŒŒì¼ ìƒì„±: config_cifar_safe.py")
        
        return 'config_cifar_safe.py'

def create_label_safe_main():
    """ë¼ë²¨ ì•ˆì „ ê²€ì¦ì´ í¬í•¨ëœ main.py ìˆ˜ì • ì‚¬í•­ ìƒì„±"""
    
    print("\nðŸ”§ ë¼ë²¨ ì•ˆì „ ê²€ì¦ ì½”ë“œ ìƒì„± ì¤‘...")
    
    safe_influence_function = '''
def compute_influence_scores_enhanced_safe(model, source_loader, target_batch, num_samples=100):
    """ì•ˆì „í•œ ì˜í–¥ë„ ê³„ì‚° (CIFAR í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ í•´ê²°)"""
    print("ðŸ” ì•ˆì „í•œ ì˜í–¥ë„ ì ìˆ˜ ê³„ì‚° ì¤‘...")
    
    model.eval()
    criterion = nn.CrossEntropyLoss()
    
    target_data, target_labels = target_batch
    target_data, target_labels = target_data.to(device), target_labels.to(device)
    
    # ðŸš¨ ëª¨ë¸ í´ëž˜ìŠ¤ ìˆ˜ í™•ì¸
    if hasattr(model, 'fc'):
        num_classes = model.fc.out_features
    elif hasattr(model, 'classifier'):
        num_classes = model.classifier[-1].out_features
    else:
        num_classes = 10  # ê¸°ë³¸ê°’
    
    print(f"ðŸ“Š ëª¨ë¸ í´ëž˜ìŠ¤ ìˆ˜: {num_classes}")
    print(f"ðŸŽ¯ ì›ë³¸ íƒ€ê²Ÿ ë¼ë²¨ ë²”ìœ„: {target_labels.min().item()} ~ {target_labels.max().item()}")
    
    # ðŸ”§ ë¼ë²¨ í´ë¦¬í•‘ (ê°•ì œë¡œ ëª¨ë¸ í´ëž˜ìŠ¤ ìˆ˜ì— ë§žì¶¤)
    target_labels_safe = torch.clamp(target_labels, 0, num_classes - 1)
    clipped_count = (target_labels != target_labels_safe).sum().item()
    
    if clipped_count > 0:
        print(f"ðŸ”§ í´ë¦¬í•‘ëœ ë¼ë²¨ ìˆ˜: {clipped_count}ê°œ")
        print(f"âœ… ì•ˆì „í•œ íƒ€ê²Ÿ ë¼ë²¨ ë²”ìœ„: {target_labels_safe.min().item()} ~ {target_labels_safe.max().item()}")
    
    # ì•ˆì „í•œ ë¼ë²¨ë¡œ ì†ì‹¤ ê³„ì‚°
    model.zero_grad()
    target_output = model(target_data)
    target_loss = criterion(target_output, target_labels_safe)
    target_loss.backward()
    
    # ë‚˜ë¨¸ì§€ ì˜í–¥ë„ ê³„ì‚° ë¡œì§...
    influence_scores = []
    sample_count = 0
    invalid_samples = 0
    
    print(f"ðŸŽ¯ {num_samples}ê°œ ìƒ˜í”Œì˜ ì˜í–¥ë„ ê³„ì‚°...")
    
    for batch_idx, (data, labels) in enumerate(source_loader):
        if sample_count >= num_samples:
            break
            
        data, labels = data.to(device), labels.to(device)
        
        # ì†ŒìŠ¤ ë¼ë²¨ë„ ì•ˆì „í•˜ê²Œ í´ë¦¬í•‘
        labels_safe = torch.clamp(labels, 0, num_classes - 1)
        
        for i in range(min(len(data), num_samples - sample_count)):
            try:
                model.zero_grad()
                output = model(data[i:i+1])
                loss = criterion(output, labels_safe[i:i+1])
                loss.backward()
                
                # ë‹¨ìˆœí™”ëœ ì˜í–¥ë„ ê³„ì‚°
                influence_scores.append(loss.item())
                sample_count += 1
                
            except Exception as e:
                print(f"âš ï¸ ìƒ˜í”Œ ê±´ë„ˆë›°ê¸°: {e}")
                invalid_samples += 1
                continue
        
        if sample_count >= num_samples:
            break
    
    print(f"âœ… {len(influence_scores)}ê°œ ìƒ˜í”Œ ì˜í–¥ë„ ê³„ì‚° ì™„ë£Œ")
    if invalid_samples > 0:
        print(f"âš ï¸ ê±´ë„ˆë›´ ìƒ˜í”Œ: {invalid_samples}ê°œ")
    
    return influence_scores
'''
    
    print("âœ… ì•ˆì „í•œ ì˜í–¥ë„ ê³„ì‚° í•¨ìˆ˜ ìƒì„± ì™„ë£Œ")
    return safe_influence_function

def generate_cifar_fix_commands():
    """CIFAR ë¬¸ì œ í•´ê²° ëª…ë ¹ì–´ ìƒì„±"""
    
    print("\nðŸ’¡ CIFAR10â†’CIFAR100 ì˜¤ë¥˜ í•´ê²° ë°©ë²•:")
    print("="*60)
    
    print("ðŸ”§ ì¦‰ì‹œ í•´ê²° ë°©ë²•:")
    print("1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:")
    print("   set CUDA_LAUNCH_BLOCKING=1")
    print("   set TORCH_USE_CUDA_DSA=1")
    
    print("\n2. ì•ˆì „í•œ ì‹¤í—˜ ì‹¤í–‰:")
    print("   python multi_dataset_experiments.py")
    print("   â†’ ìžì—° ì´ë¯¸ì§€ ë„ë©”ì¸ ì„ íƒ â†’ CIFAR10â†’CIFAR100 ì„ íƒ")
    
    print("\n3. ìˆ˜ë™ ì•ˆì „ ì‹¤í–‰:")
    print("   # ë¼ë²¨ í´ë¦¬í•‘ ëª¨ë“œ")
    print("   CUDA_LAUNCH_BLOCKING=1 python main.py --source_dataset CIFAR10 --target_dataset CIFAR100 --batch_size 64 --influence_samples 100")
    
    print("\nðŸš¨ í•µì‹¬ í•´ê²°ì±…:")
    print("   â€¢ ëª¨ë¸ í´ëž˜ìŠ¤ ìˆ˜: 100ê°œë¡œ í†µì¼ (CIFAR100 ê¸°ì¤€)")
    print("   â€¢ ë¼ë²¨ í´ë¦¬í•‘: CIFAR100 ë¼ë²¨ â†’ 0-9 ë²”ìœ„ë¡œ ì œí•œ")
    print("   â€¢ ë°°ì¹˜ í¬ê¸°: 64ë¡œ ê°ì†Œ")
    print("   â€¢ ì˜í–¥ë„ ìƒ˜í”Œ: 100ê°œë¡œ ëŒ€í­ ê°ì†Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ðŸ”§ CIFAR10 â†” CIFAR100 í´ëž˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ í•´ê²° ë„êµ¬")
    print("="*60)
    print("ë¬¸ì œ: CIFAR10(10í´ëž˜ìŠ¤) â†’ CIFAR100(100í´ëž˜ìŠ¤) ì˜í–¥ë„ ê³„ì‚° ì˜¤ë¥˜")
    print("ì›ì¸: Assertion `t >= 0 && t < n_classes` failed")
    print("="*60)
    
    # 1. ë¬¸ì œ ë¶„ì„
    datasets = analyze_cifar_mismatch()
    
    # 2. ì•ˆì „ ì„¤ì • ìƒì„±
    safe_configs = create_cifar_safe_config()
    
    # 3. ì‹¤í—˜ ì„¤ì • íŒŒì¼ ìƒì„±
    config_file = generate_cifar_experiment_config()
    
    # 4. ì•ˆì „ í•¨ìˆ˜ ìƒì„±
    safe_function = create_label_safe_main()
    
    # 5. í•´ê²° ëª…ë ¹ì–´ ì¶œë ¥
    generate_cifar_fix_commands()
    
    print(f"\nðŸŽ‰ CIFAR ë¬¸ì œ í•´ê²° ë„êµ¬ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"ðŸ“ ìƒì„±ëœ íŒŒì¼: {config_file}")

if __name__ == "__main__":
    main() 