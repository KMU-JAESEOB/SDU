# download_officehome.py
"""
ğŸ  Office-Home ê³µì‹ ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •
- ê³µì‹ ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ
- ì••ì¶• í•´ì œ ë° ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •
- ë°ì´í„° ê²€ì¦ ë° í†µê³„ ì •ë³´ ì¶œë ¥
"""

import os
import sys
import urllib.request
import zipfile
import tarfile
import shutil
from pathlib import Path
import json
import time
from tqdm import tqdm
import hashlib

class OfficeHomeDownloader:
    """Office-Home ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ê´€ë¦¬ì"""
    
    def __init__(self, root_dir='./data'):
        self.root_dir = Path(root_dir)
        self.officehome_dir = self.root_dir / 'OfficeHome'
        
        # Office-Home ê³µì‹ ë‹¤ìš´ë¡œë“œ ì •ë³´
        self.download_info = {
            'dataset_name': 'Office-Home',
            'total_size': '2.1GB',
            'num_classes': 65,
            'num_images': 15588,
            'domains': {
                'Art': 2427,
                'Clipart': 4365,
                'Product': 4439,
                'Real World': 4357
            },
            # ê³µì‹ ë‹¤ìš´ë¡œë“œ URLë“¤ (ì‹¤ì œ URLë¡œ ì—…ë°ì´íŠ¸ í•„ìš”)
            'urls': {
                'official_site': 'https://www.hemanthdv.org/officeHomeDataset.html',
                'google_drive': 'https://drive.google.com/uc?id=0B81rNlvomiwed0V1YUxQdC1uOTg',
                'backup_url': 'https://dataset-mirrors.example.com/officehome.zip'  # ë°±ì—… URL
            },
            'file_info': {
                'filename': 'OfficeHome.zip',
                'md5_hash': 'placeholder_hash',  # ì‹¤ì œ í•´ì‹œê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•„ìš”
                'extracted_size': '3.2GB'
            }
        }
        
        print("ğŸ  Office-Home ë‹¤ìš´ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ!")
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {self.root_dir}")
        print(f"ğŸ¯ íƒ€ê²Ÿ ë””ë ‰í† ë¦¬: {self.officehome_dir}")
    
    def check_existing_data(self):
        """ê¸°ì¡´ ë°ì´í„°ì…‹ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        
        print("\nğŸ” ê¸°ì¡´ ë°ì´í„°ì…‹ í™•ì¸ ì¤‘...")
        
        if not self.officehome_dir.exists():
            print("âŒ Office-Home ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
        
        # í•„ìˆ˜ ë„ë©”ì¸ ë””ë ‰í† ë¦¬ í™•ì¸
        required_domains = ['Art', 'Clipart', 'Product', 'Real World']
        missing_domains = []
        
        for domain in required_domains:
            domain_path = self.officehome_dir / domain
            if not domain_path.exists():
                missing_domains.append(domain)
            else:
                # ë„ë©”ì¸ë³„ ìƒ˜í”Œ ìˆ˜ í™•ì¸
                sample_count = len(list(domain_path.rglob('*.jpg')))
                expected_count = self.download_info['domains'][domain]
                print(f"ğŸ“¦ {domain}: {sample_count:,}ê°œ (ì˜ˆìƒ: {expected_count:,}ê°œ)")
        
        if missing_domains:
            print(f"âŒ ëˆ„ë½ëœ ë„ë©”ì¸: {', '.join(missing_domains)}")
            return False
        
        print("âœ… ëª¨ë“  ë„ë©”ì¸ ë””ë ‰í† ë¦¬ ì¡´ì¬")
        return True
    
    def download_progress_hook(self, block_num, block_size, total_size):
        """ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ"""
        downloaded = block_num * block_size
        percent = min(100, (downloaded / total_size) * 100)
        
        if hasattr(self, '_last_percent'):
            if percent - self._last_percent < 1:  # 1% ë‹¨ìœ„ë¡œë§Œ ì—…ë°ì´íŠ¸
                return
        
        self._last_percent = percent
        bar_length = 50
        filled_length = int(bar_length * percent / 100)
        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
        
        downloaded_mb = downloaded / (1024 * 1024)
        total_mb = total_size / (1024 * 1024)
        
        print(f'\rğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: |{bar}| {percent:.1f}% ({downloaded_mb:.1f}/{total_mb:.1f} MB)', end='')
    
    def download_from_google_drive(self, file_id, destination):
        """Google Driveì—ì„œ Office-Home ë‹¤ìš´ë¡œë“œ"""
        
        print(f"\nğŸ“¥ Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        # Google Drive ë‹¤ìš´ë¡œë“œ URL êµ¬ì„±
        base_url = "https://drive.google.com/uc"
        params = f"?export=download&id={file_id}"
        
        try:
            # íŒŒì¼ í¬ê¸° í™•ì¸ì„ ìœ„í•œ HEAD ìš”ì²­
            import urllib.request
            req = urllib.request.Request(base_url + params, method='HEAD')
            with urllib.request.urlopen(req) as response:
                file_size = int(response.headers.get('Content-Length', 0))
            
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size / (1024*1024*1024):.2f} GB")
            
            # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ
            urllib.request.urlretrieve(
                base_url + params,
                destination,
                reporthook=self.download_progress_hook
            )
            
            print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {destination}")
            return True
            
        except Exception as e:
            print(f"\nâŒ Google Drive ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def download_from_url(self, url, destination):
        """ì¼ë°˜ URLì—ì„œ ë‹¤ìš´ë¡œë“œ"""
        
        print(f"\nğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")
        
        try:
            urllib.request.urlretrieve(
                url, destination, reporthook=self.download_progress_hook
            )
            print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {destination}")
            return True
        except Exception as e:
            print(f"\nâŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def extract_archive(self, archive_path):
        """ì••ì¶• íŒŒì¼ í•´ì œ"""
        
        print(f"\nğŸ“¦ ì••ì¶• í•´ì œ ì¤‘: {archive_path}")
        
        try:
            if archive_path.suffix == '.zip':
                with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                    # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ì••ì¶• í•´ì œ
                    file_list = zip_ref.namelist()
                    
                    with tqdm(total=len(file_list), desc="ì••ì¶• í•´ì œ") as pbar:
                        for file in file_list:
                            zip_ref.extract(file, self.root_dir)
                            pbar.update(1)
            
            elif archive_path.suffix in ['.tar', '.gz', '.tgz']:
                with tarfile.open(archive_path, 'r:*') as tar_ref:
                    tar_ref.extractall(self.root_dir)
            
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì••ì¶• í˜•ì‹: {archive_path.suffix}")
            
            print("âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ ì••ì¶• í•´ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def verify_dataset(self):
        """ë°ì´í„°ì…‹ ë¬´ê²°ì„± ê²€ì¦"""
        
        print("\nğŸ” ë°ì´í„°ì…‹ ê²€ì¦ ì¤‘...")
        
        verification_results = {
            'total_images': 0,
            'total_classes': set(),
            'domain_stats': {},
            'issues': []
        }
        
        for domain_name in self.download_info['domains'].keys():
            domain_path = self.officehome_dir / domain_name
            
            if not domain_path.exists():
                verification_results['issues'].append(f"ë„ë©”ì¸ ë””ë ‰í† ë¦¬ ëˆ„ë½: {domain_name}")
                continue
            
            domain_images = 0
            domain_classes = set()
            
            for class_dir in domain_path.iterdir():
                if class_dir.is_dir():
                    class_name = class_dir.name
                    domain_classes.add(class_name)
                    verification_results['total_classes'].add(class_name)
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ ì¹´ìš´íŠ¸
                    images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))
                    domain_images += len(images)
            
            verification_results['domain_stats'][domain_name] = {
                'images': domain_images,
                'classes': len(domain_classes),
                'expected_images': self.download_info['domains'][domain_name]
            }
            
            verification_results['total_images'] += domain_images
            
            # ì˜ˆìƒ ì´ë¯¸ì§€ ìˆ˜ì™€ ë¹„êµ
            expected = self.download_info['domains'][domain_name]
            if abs(domain_images - expected) > expected * 0.1:  # 10% ì˜¤ì°¨ í—ˆìš©
                verification_results['issues'].append(
                    f"{domain_name}: ì´ë¯¸ì§€ ìˆ˜ ë¶ˆì¼ì¹˜ ({domain_images} vs {expected})"
                )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼:")
        print(f"   ğŸ–¼ï¸ ì´ ì´ë¯¸ì§€: {verification_results['total_images']:,}ê°œ")
        print(f"   ğŸ¯ ì´ í´ë˜ìŠ¤: {len(verification_results['total_classes'])}ê°œ")
        
        for domain, stats in verification_results['domain_stats'].items():
            status = "âœ…" if stats['images'] == stats['expected_images'] else "âš ï¸"
            print(f"   {status} {domain}: {stats['images']:,}ê°œ ì´ë¯¸ì§€, {stats['classes']}ê°œ í´ë˜ìŠ¤")
        
        if verification_results['issues']:
            print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in verification_results['issues']:
                print(f"   - {issue}")
            return False
        else:
            print(f"\nâœ… ë°ì´í„°ì…‹ ê²€ì¦ ì™„ë£Œ! ëª¨ë“  ë°ì´í„°ê°€ ì •ìƒì…ë‹ˆë‹¤.")
            return True
    
    def create_dataset_info(self):
        """ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ ìƒì„±"""
        
        print("\nğŸ“ ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ ìƒì„± ì¤‘...")
        
        info = {
            'dataset_name': 'Office-Home',
            'download_date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'source': 'Official Office-Home Dataset',
            'url': self.download_info['urls']['official_site'],
            'total_images': 0,
            'total_classes': 65,
            'domains': {}
        }
        
        # ì‹¤ì œ í†µê³„ ìˆ˜ì§‘
        for domain_name in self.download_info['domains'].keys():
            domain_path = self.officehome_dir / domain_name
            
            if domain_path.exists():
                images = list(domain_path.rglob('*.jpg')) + list(domain_path.rglob('*.png'))
                classes = set([img.parent.name for img in images])
                
                info['domains'][domain_name] = {
                    'images': len(images),
                    'classes': len(classes),
                    'class_list': sorted(list(classes))
                }
                
                info['total_images'] += len(images)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        info_file = self.officehome_dir / 'dataset_info.json'
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥: {info_file}")
        return info
    
    def download_official_dataset(self):
        """ê³µì‹ Office-Home ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        
        print("\nğŸš€ Office-Home ê³µì‹ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘!")
        print("="*60)
        
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        if self.check_existing_data():
            response = input("\nâœ… ê¸°ì¡´ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() != 'y':
                print("â­ï¸ ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆë›°ê³  ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self.verify_dataset()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.root_dir.mkdir(parents=True, exist_ok=True)
        
        # ë‹¤ìš´ë¡œë“œ íŒŒì¼ ê²½ë¡œ
        download_file = self.root_dir / self.download_info['file_info']['filename']
        
        # ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì—¬ëŸ¬ ì†ŒìŠ¤)
        download_success = False
        
        print(f"\nğŸ“‹ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´:")
        print(f"1. ê³µì‹ ì›¹ì‚¬ì´íŠ¸: {self.download_info['urls']['official_site']}")
        print(f"2. ì˜ˆìƒ íŒŒì¼ í¬ê¸°: {self.download_info['total_size']}")
        print(f"3. ì••ì¶• í•´ì œ í›„ í¬ê¸°: {self.download_info['file_info']['extracted_size']}")
        
        # ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
        print(f"\nğŸ“¥ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ë°©ë²•:")
        print(f"1. {self.download_info['urls']['official_site']} ë°©ë¬¸")
        print(f"2. OfficeHome ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ")
        print(f"3. ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì„ {download_file} ê²½ë¡œì— ì €ì¥")
        print(f"4. ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if download_file.exists():
            print(f"\nâœ… ë‹¤ìš´ë¡œë“œ íŒŒì¼ ë°œê²¬: {download_file}")
        else:
            print(f"\nâš ï¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            print(f"íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•œ í›„ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥í•˜ì„¸ìš”: {download_file}")
            
            response = input("ë‹¤ìš´ë¡œë“œë¥¼ ì™„ë£Œí•˜ì…¨ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() != 'y':
                print("âŒ ë‹¤ìš´ë¡œë“œë¥¼ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                return False
        
        # ì••ì¶• í•´ì œ
        if download_file.exists():
            print(f"\nğŸ“¦ ì••ì¶• íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            
            if self.extract_archive(download_file):
                # ì••ì¶• íŒŒì¼ ì‚­ì œ (ì„ íƒì‚¬í•­)
                response = input(f"\nğŸ—‘ï¸ ì••ì¶• íŒŒì¼ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? ({download_file.name}) (y/N): ")
                if response.lower() == 'y':
                    download_file.unlink()
                    print("âœ… ì••ì¶• íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                
                # ë°ì´í„°ì…‹ ê²€ì¦
                if self.verify_dataset():
                    # ì •ë³´ íŒŒì¼ ìƒì„±
                    self.create_dataset_info()
                    
                    print(f"\nğŸ‰ Office-Home ë°ì´í„°ì…‹ ì„¤ì • ì™„ë£Œ!")
                    print(f"ğŸ“ ë°ì´í„° ìœ„ì¹˜: {self.officehome_dir}")
                    print(f"ğŸ¯ 4ê°œ ë„ë©”ì¸, 65ê°œ í´ë˜ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
                    return True
        
        print(f"\nâŒ ë°ì´í„°ì…‹ ì„¤ì • ì‹¤íŒ¨")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ  Office-Home ê³µì‹ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë”")
    print("="*60)
    
    # ë‹¤ìš´ë¡œë” ìƒì„±
    downloader = OfficeHomeDownloader()
    
    # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
    success = downloader.download_official_dataset()
    
    if success:
        print(f"\nğŸ‰ ì„¤ì • ì™„ë£Œ! ì´ì œ Office-Home ì‹¤í—˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"ì‹¤í–‰ ëª…ë ¹ì–´: python officehome_full_experiments.py")
    else:
        print(f"\nâŒ ì„¤ì • ì‹¤íŒ¨. ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    return success

if __name__ == "__main__":
    main() 