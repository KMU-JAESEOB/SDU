#!/usr/bin/env python3
# office31_full_experiments.py - Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© ì‹¤í—˜

"""
ğŸ¢ Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© SDA-U ì‹¤í—˜

Office-31ì˜ 6ê°€ì§€ ë„ë©”ì¸ ì¡°í•©ì— ëŒ€í•´ SDA-U ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ê³ 
ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ë„ë©”ì¸ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

ì‹¤í—˜ ì¡°í•©:
1. Amazon â†’ Webcam (ê³ í’ˆì§ˆ â†’ ì €í’ˆì§ˆ)
2. Amazon â†’ DSLR (ì¸ê³µì  â†’ ìì—°ìŠ¤ëŸ¬ìš´)  
3. Webcam â†’ Amazon (ì €í’ˆì§ˆ â†’ ê³ í’ˆì§ˆ)
4. Webcam â†’ DSLR (ì €í’ˆì§ˆ â†’ ê³ í’ˆì§ˆ)
5. DSLR â†’ Amazon (ìì—°ìŠ¤ëŸ¬ìš´ â†’ ì¸ê³µì )
6. DSLR â†’ Webcam (ê³ í’ˆì§ˆ â†’ ì €í’ˆì§ˆ)
"""

import os
import json
import time
import subprocess
from datetime import datetime
from pathlib import Path

class Office31FullExperiments:
    """Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© ì‹¤í—˜ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.results_dir = Path('office31_results')
        self.results_dir.mkdir(exist_ok=True)
        
        # Office-31 ë„ë©”ì¸ ì¡°í•© ì •ì˜
        self.domain_combinations = [
            ('Office31_Amazon', 'Office31_Webcam', 'Amazonâ†’Webcam: ê³ í’ˆì§ˆâ†’ì €í’ˆì§ˆ'),
            ('Office31_Amazon', 'Office31_DSLR', 'Amazonâ†’DSLR: ì¸ê³µì â†’ìì—°ìŠ¤ëŸ¬ìš´'),
            ('Office31_Webcam', 'Office31_Amazon', 'Webcamâ†’Amazon: ì €í’ˆì§ˆâ†’ê³ í’ˆì§ˆ'),
            ('Office31_Webcam', 'Office31_DSLR', 'Webcamâ†’DSLR: ì €í’ˆì§ˆâ†’ê³ í’ˆì§ˆ'),
            ('Office31_DSLR', 'Office31_Amazon', 'DSLRâ†’Amazon: ìì—°ìŠ¤ëŸ¬ìš´â†’ì¸ê³µì '),
            ('Office31_DSLR', 'Office31_Webcam', 'DSLRâ†’Webcam: ê³ í’ˆì§ˆâ†’ì €í’ˆì§ˆ')
        ]
        
        # ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš©
        self.all_results = []
        
    def create_experiment_config(self, source_dataset, target_dataset, experiment_name):
        """íŠ¹ì • ë„ë©”ì¸ ì¡°í•©ì„ ìœ„í•œ config.py ìƒì„± (Office-31 í˜¸í™˜ì„± ê°•í™”)"""
        
        # ğŸ¯ ë„ë©”ì¸ë³„ ì ì‘ ì—í¬í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
        domain_epochs_dict = {
            'Amazon2Webcam': 10,     # ì¤‘ê°„ ë‚œì´ë„
            'Amazon2DSLR': 8,        # ìƒëŒ€ì ìœ¼ë¡œ ì‰¬ì›€
            'Webcam2Amazon': 12,     # ì–´ë ¤ì›€ (ì‘ì€â†’í° ë°ì´í„°ì…‹)
            'Webcam2DSLR': 8,        # ì¤‘ê°„
            'DSLR2Amazon': 12,       # ì–´ë ¤ì›€ (ì‘ì€â†’í° ë°ì´í„°ì…‹)  
            'DSLR2Webcam': 10        # ì¤‘ê°„ ë‚œì´ë„
        }
        
        # ë”•ì…”ë„ˆë¦¬ë¥¼ ì•ˆì „í•œ ë¬¸ìì—´ë¡œ ë³€í™˜
        domain_epochs_str = "{\n"
        for key, value in domain_epochs_dict.items():
            domain_epochs_str += f"    '{key}': {value},     # ë„ë©”ì¸ë³„ ì„¤ì •\n"
        domain_epochs_str += "}"
        
        config_content = f'''# config.py - Office-31 ì‹¤í—˜ìš© ì„¤ì • ({experiment_name}) - ì„±ëŠ¥ ìµœì í™”

# ============================================
# ğŸ¢ Office-31 ì‹¤í—˜: {experiment_name} (ê³ ì„±ëŠ¥ ì„¤ì •)
# ============================================
ARCHITECTURE = 'resnet50'  # Office-31ì— ìµœì í™”ëœ ì•„í‚¤í…ì²˜ (ê³ ì •)
BATCH_SIZE = 64           # A100ì— ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸° (32â†’64)
NUM_EPOCHS = 15           # ì¶©ë¶„í•œ í•™ìŠµì„ ìœ„í•œ ì—í¬í¬ (5â†’15)
LEARNING_RATE = 2e-4      # ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ì— ì í•©í•œ í•™ìŠµë¥  (1e-4â†’2e-4)

# ë°ì´í„°ì…‹ ì„¤ì •
SOURCE_DATASET = '{source_dataset}'
TARGET_DATASET = '{target_dataset}'

# SDA-U ì•Œê³ ë¦¬ì¦˜ ì„¤ì • (ì„±ëŠ¥ ìµœì í™”)
TARGET_SUBSET_SIZE = 600     # ë” ë§ì€ íƒ€ê²Ÿ ìƒ˜í”Œ ì‚¬ìš© (500â†’600)
NUM_UNLEARN_STEPS = 8        # ë” ì •êµí•œ ì–¸ëŸ¬ë‹ (5â†’8)
INFLUENCE_SAMPLES = 300      # ë” ë§ì€ ì˜í–¥ë„ ìƒ˜í”Œ (200â†’300)
ADAPTATION_EPOCHS = 10       # ì ì‘ í›ˆë ¨ ì—í¬í¬ (8â†’10, ë„ë©”ì¸ë³„ ì¡°ì • ê°€ëŠ¥)
MAX_UNLEARN_SAMPLES = 150    # ë” ë§ì€ ì–¸ëŸ¬ë‹ ìƒ˜í”Œ (100â†’150)

# ğŸ”„ ë‹¤ì¤‘ ë¼ìš´ë“œ SDA-U ì„¤ì •
SDA_U_ROUNDS = 1            # SDA-U ë¼ìš´ë“œ ìˆ˜
PROGRESSIVE_UNLEARNING = True  # ì ì§„ì  ì–¸ëŸ¬ë‹ ì—¬ë¶€
DYNAMIC_THRESHOLD = True    # ë™ì  ì„ê³„ê°’ ì¡°ì • ì—¬ë¶€

# ğŸ¯ ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€!)
USE_PRETRAINED = True       # ImageNet ì‚¬ì „ í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©
FREEZE_BACKBONE = False     # ë°±ë³¸ ê³ ì • ì—¬ë¶€ (False=fine-tuning)

# ğŸ”§ ê³ ê¸‰ í›ˆë ¨ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€!)
SCHEDULER_TYPE = 'cosine'   # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ('cosine', 'step', 'none')
WARMUP_EPOCHS = 2          # ì›Œë°ì—… ì—í¬í¬
WEIGHT_DECAY = 1e-4        # ê°€ì¤‘ì¹˜ ê°ì‡ 
GRADIENT_CLIP = 1.0        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘

# í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ íŒŒë¼ë¯¸í„°
LAMBDA_U = 0.6
BETA = 0.1

# ì €ì¥ ì„¤ì •
SAVE_MODELS = True
SAVE_RESULTS = True
QUICK_TEST = False  # ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì •

# ğŸ¯ ë„ë©”ì¸ë³„ ì ì‘ ì—í¬í¬ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€!)
DOMAIN_SPECIFIC_EPOCHS = {domain_epochs_str}

def get_config():
    """ì„¤ì •ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (Office-31 ê³ ì„±ëŠ¥ ìµœì í™”)"""
    import torch
    
    # GPU ìµœì í™” (A100ì—ì„œë„ ResNet50 ê°•ì œ ì‚¬ìš©)
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        if "A100" in gpu_name:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            print("ğŸš€ A100 ìµœì í™” í™œì„±í™”! (ê³ ì„±ëŠ¥ ì„¤ì •)")
    
    # ğŸš¨ ì¤‘ìš”: ê³ ì„±ëŠ¥ ì„¤ì •ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
    return {{
        'architecture': 'resnet50',
        'batch_size': BATCH_SIZE,
        'num_epochs': NUM_EPOCHS,
        'learning_rate': LEARNING_RATE,
        'target_subset_size': TARGET_SUBSET_SIZE,
        'num_unlearn_steps': NUM_UNLEARN_STEPS,
        'influence_samples': INFLUENCE_SAMPLES,
        'adaptation_epochs': ADAPTATION_EPOCHS,
        'max_unlearn_samples': MAX_UNLEARN_SAMPLES,
        'sda_u_rounds': SDA_U_ROUNDS,
        'progressive_unlearning': PROGRESSIVE_UNLEARNING,
        'dynamic_threshold': DYNAMIC_THRESHOLD,
        'use_pretrained': USE_PRETRAINED,
        'freeze_backbone': FREEZE_BACKBONE,
        'scheduler_type': SCHEDULER_TYPE,
        'warmup_epochs': WARMUP_EPOCHS,
        'weight_decay': WEIGHT_DECAY,
        'gradient_clip': GRADIENT_CLIP,
        'lambda_u': LAMBDA_U,
        'beta': BETA,
        'save_models': SAVE_MODELS,
        'save_results': SAVE_RESULTS,
        'quick_test': QUICK_TEST,
        'source_dataset': SOURCE_DATASET,
        'target_dataset': TARGET_DATASET,
        'domain_specific_epochs': DOMAIN_SPECIFIC_EPOCHS,
        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'
    }}
'''
        
        with open('config.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
            
    def run_single_experiment(self, source_dataset, target_dataset, description):
        """ë‹¨ì¼ ë„ë©”ì¸ ì¡°í•© ì‹¤í—˜ ì‹¤í–‰ (ì²´ê³„ì  íŒŒì¼ ê´€ë¦¬)"""
        
        experiment_name = f"{source_dataset.split('_')[1]}2{target_dataset.split('_')[1]}"
        
        print(f"\n{'='*80}")
        print(f"ğŸ§ª ì‹¤í—˜ ì‹œì‘: {experiment_name}")
        print(f"ğŸ“Š {description}")
        print(f"ğŸ“¤ ì†ŒìŠ¤: {source_dataset}")
        print(f"ğŸ“¥ íƒ€ê²Ÿ: {target_dataset}")
        print(f"{'='*80}")
        
        # ğŸ—‚ï¸ ì‹¤í—˜ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
        experiment_dir = self.results_dir / experiment_name
        experiment_dir.mkdir(exist_ok=True)
        
        models_dir = Path('models') / experiment_name
        models_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ ì‹¤í—˜ ë””ë ‰í† ë¦¬: {experiment_dir}")
        print(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬: {models_dir}")
        
        # config.py ë°±ì—…
        if os.path.exists('config.py.backup'):
            os.remove('config.py.backup')
        if os.path.exists('config.py'):
            os.rename('config.py', 'config.py.backup')
        
        try:
            # ì‹¤í—˜ìš© config.py ìƒì„±
            self.create_experiment_config(source_dataset, target_dataset, experiment_name)
            
            # ì‹¤í—˜ ì‹¤í–‰
            start_time = time.time()
            print("ğŸš€ SDA-U ì‹¤í—˜ ì‹¤í–‰ ì¤‘...")
            
            process = subprocess.Popen(['python', 'main.py'], 
                                     stdout=subprocess.PIPE, 
                                     stderr=subprocess.STDOUT,
                                     text=True, 
                                     bufsize=1)
            
            # ì‹¤ì‹œê°„ ì¶œë ¥ ë° ë¡œê·¸ ì €ì¥
            output_lines = []
            log_file = experiment_dir / f"{experiment_name}_execution_log.txt"
            
            with open(log_file, 'w', encoding='utf-8') as log:
                while True:
                    if process.stdout is None:
                        break
                    output = process.stdout.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        print(output.strip())
                        log.write(output)
                        log.flush()
                        output_lines.append(output.strip())
            
            return_code = process.poll()
            end_time = time.time()
            execution_time = end_time - start_time
            
            if return_code == 0:
                print(f"âœ… ì‹¤í—˜ ì™„ë£Œ! (ì‹¤í–‰ì‹œê°„: {execution_time:.1f}ì´ˆ)")
                
                # ğŸ—‚ï¸ ê²°ê³¼ íŒŒì¼ ì²´ê³„ì  ê´€ë¦¬
                result_file = 'results/sda_u_comprehensive_results.json'
                if os.path.exists(result_file):
                    # ê²°ê³¼ ë¡œë“œ ë° ì¶”ê°€ ì •ë³´ ì‚½ì…
                    with open(result_file, 'r', encoding='utf-8') as f:
                        result_data = json.load(f)
                    
                    # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    result_data['experiment_info']['experiment_name'] = experiment_name
                    result_data['experiment_info']['source_dataset'] = source_dataset
                    result_data['experiment_info']['target_dataset'] = target_dataset
                    result_data['experiment_info']['description'] = description
                    result_data['experiment_info']['execution_time_seconds'] = execution_time
                    result_data['experiment_info']['log_file'] = str(log_file)
                    result_data['experiment_info']['models_directory'] = str(models_dir)
                    
                    # ğŸ—‚ï¸ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ê²°ê³¼ ì €ì¥
                    # 1. ë©”ì¸ ê²°ê³¼ íŒŒì¼
                    main_result_file = experiment_dir / f"{experiment_name}_results.json"
                    with open(main_result_file, 'w', encoding='utf-8') as f:
                        json.dump(result_data, f, indent=2, ensure_ascii=False)
                    
                    # 2. ì„±ëŠ¥ ìš”ì•½ íŒŒì¼
                    performance_summary = self.extract_performance_summary(result_data)
                    summary_file = experiment_dir / f"{experiment_name}_performance_summary.json"
                    with open(summary_file, 'w', encoding='utf-8') as f:
                        json.dump(performance_summary, f, indent=2, ensure_ascii=False)
                    
                    # 3. ë¹ ë¥¸ ì°¸ì¡°ìš© í…ìŠ¤íŠ¸ íŒŒì¼
                    quick_ref_file = experiment_dir / f"{experiment_name}_quick_reference.txt"
                    with open(quick_ref_file, 'w', encoding='utf-8') as f:
                        f.write(f"ì‹¤í—˜: {experiment_name}\n")
                        f.write(f"ì†ŒìŠ¤ â†’ íƒ€ê²Ÿ: {source_dataset} â†’ {target_dataset}\n")
                        f.write(f"ì„¤ëª…: {description}\n")
                        f.write(f"ì‹¤í–‰ì‹œê°„: {execution_time:.1f}ì´ˆ\n")
                        f.write(f"ìµœì¢… íƒ€ê²Ÿ ì •í™•ë„: {performance_summary.get('target_subset_accuracy', 0):.2f}%\n")
                        f.write(f"ì „ì²´ íƒ€ê²Ÿ ì •í™•ë„: {performance_summary.get('full_target_accuracy', 0):.2f}%\n")
                        f.write(f"ìµœê³  ì„±ëŠ¥: {performance_summary.get('best_target_accuracy', 0):.2f}%\n")
                    
                    print(f"ğŸ“‹ ë©”ì¸ ê²°ê³¼: {main_result_file}")
                    print(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½: {summary_file}")
                    print(f"âš¡ ë¹ ë¥¸ ì°¸ì¡°: {quick_ref_file}")
                    print(f"ğŸ“ ì‹¤í–‰ ë¡œê·¸: {log_file}")
                    
                    # ì „ì²´ ê²°ê³¼ì— ì¶”ê°€
                    self.all_results.append({
                        'experiment_name': experiment_name,
                        'source_dataset': source_dataset,
                        'target_dataset': target_dataset,
                        'description': description,
                        'execution_time': execution_time,
                        'result_data': result_data,
                        'files': {
                            'main_result': str(main_result_file),
                            'performance_summary': str(summary_file),
                            'quick_reference': str(quick_ref_file),
                            'execution_log': str(log_file),
                            'models_directory': str(models_dir)
                        }
                    })
                    
                    return True, result_data
                else:
                    print("âš ï¸ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return False, None
            else:
                print(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨! (ë°˜í™˜ì½”ë“œ: {return_code})")
                return False, None
                
        except Exception as e:
            print(f"âŒ ì‹¤í—˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False, None
            
        finally:
            # config.py ë³µì›
            if os.path.exists('config.py.backup'):
                if os.path.exists('config.py'):
                    os.remove('config.py')
                os.rename('config.py.backup', 'config.py')
    
    def extract_performance_summary(self, result_data):
        """ê²°ê³¼ì—ì„œ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ"""
        
        try:
            final_perf = result_data.get('final_performance', {})
            exp_info = result_data.get('experiment_info', {})
            
            return {
                'source_accuracy': final_perf.get('source_accuracy', 0),
                'target_subset_accuracy': final_perf.get('target_subset_accuracy', 0),
                'full_target_accuracy': final_perf.get('full_target_accuracy', 0),
                'improvement': final_perf.get('improvement_over_baseline', 0),
                'execution_time': exp_info.get('execution_time_seconds', 0),
                'best_target_accuracy': exp_info.get('best_target_accuracy', 0)
            }
        except Exception as e:
            print(f"âš ï¸ ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'source_accuracy': 0,
                'target_subset_accuracy': 0,
                'full_target_accuracy': 0,
                'improvement': 0,
                'execution_time': 0,
                'best_target_accuracy': 0
            }
    
    def create_performance_table(self):
        """ì„±ëŠ¥ ê²°ê³¼ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ ì •ë¦¬ (pandas ì—†ì´)"""
        
        if not self.all_results:
            print("âš ï¸ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì„±ëŠ¥ ë°ì´í„° ì¶”ì¶œ
        performance_data = []
        for result in self.all_results:
            perf = self.extract_performance_summary(result['result_data'])
            performance_data.append({
                'ì‹¤í—˜ëª…': result['experiment_name'],
                'ì†ŒìŠ¤â†’íƒ€ê²Ÿ': f"{result['source_dataset'].split('_')[1]}â†’{result['target_dataset'].split('_')[1]}",
                'ì„¤ëª…': result['description'],
                'ì†ŒìŠ¤ ì •í™•ë„(%)': f"{perf['source_accuracy']:.2f}",
                'íƒ€ê²Ÿ ì„œë¸Œì…‹ ì •í™•ë„(%)': f"{perf['target_subset_accuracy']:.2f}",
                'ì „ì²´ íƒ€ê²Ÿ ì •í™•ë„(%)': f"{perf['full_target_accuracy']:.2f}",
                'ìµœê³  íƒ€ê²Ÿ ì •í™•ë„(%)': f"{perf['best_target_accuracy']:.2f}",
                'ê°œì„ ë„(%)': f"{perf['improvement']:.2f}",
                'ì‹¤í–‰ì‹œê°„(ì´ˆ)': f"{perf['execution_time']:.1f}"
            })
        
        # CSV íŒŒì¼ë¡œ ì €ì¥ (pandas ì—†ì´)
        csv_file = self.results_dir / 'office31_performance_summary.csv'
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            if performance_data:
                # í—¤ë” ì‘ì„±
                headers = list(performance_data[0].keys())
                f.write(','.join(headers) + '\n')
                
                # ë°ì´í„° ì‘ì„±
                for row in performance_data:
                    f.write(','.join(str(row[header]) for header in headers) + '\n')
        
        print(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” ì €ì¥: {csv_file}")
        
        return performance_data
    
    def print_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ì„ ì½˜ì†”ì— ì¶œë ¥"""
        
        if not self.all_results:
            print("âš ï¸ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n{'='*100}")
        print("ğŸ“Š Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*100}")
        
        # í…Œì´ë¸” í—¤ë”
        print(f"{'ì‹¤í—˜ëª…':<15} {'ë„ë©”ì¸ ì¡°í•©':<20} {'ì†ŒìŠ¤ ì •í™•ë„':<12} {'íƒ€ê²Ÿ ì •í™•ë„':<12} {'ìµœê³  ì •í™•ë„':<12} {'ì‹¤í–‰ì‹œê°„':<10}")
        print("-" * 100)
        
        # ê° ì‹¤í—˜ ê²°ê³¼ ì¶œë ¥
        total_time = 0
        best_experiment = None
        best_accuracy = 0
        
        for result in self.all_results:
            perf = self.extract_performance_summary(result['result_data'])
            
            print(f"{result['experiment_name']:<15} "
                  f"{result['source_dataset'].split('_')[1]}â†’{result['target_dataset'].split('_')[1]:<19} "
                  f"{perf['source_accuracy']:<11.2f}% "
                  f"{perf['full_target_accuracy']:<11.2f}% "
                  f"{perf['best_target_accuracy']:<11.2f}% "
                  f"{perf['execution_time']:<9.1f}s")
            
            total_time += perf['execution_time']
            
            if perf['best_target_accuracy'] > best_accuracy:
                best_accuracy = perf['best_target_accuracy']
                best_experiment = result['experiment_name']
        
        print("-" * 100)
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥: {best_experiment} ({best_accuracy:.2f}%)")
        print(f"â±ï¸ ì´ ì‹¤í–‰ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"ğŸ“ ìƒì„¸ ê²°ê³¼: {self.results_dir}/")
    
    def save_comprehensive_report(self):
        """ì¢…í•© ë³´ê³ ì„œ ì €ì¥"""
        
        report = {
            'experiment_info': {
                'total_experiments': len(self.all_results),
                'timestamp': datetime.now().isoformat(),
                'framework': 'SDA-U Office-31 Full Domain Adaptation',
                'domain_combinations': len(self.domain_combinations)
            },
            'performance_summary': [],
            'detailed_results': self.all_results
        }
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶”ê°€
        for result in self.all_results:
            perf = self.extract_performance_summary(result['result_data'])
            report['performance_summary'].append({
                'experiment_name': result['experiment_name'],
                'source_dataset': result['source_dataset'],
                'target_dataset': result['target_dataset'],
                'description': result['description'],
                'performance': perf
            })
        
        # ì¢…í•© ë³´ê³ ì„œ ì €ì¥
        report_file = self.results_dir / 'office31_comprehensive_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ ì¢…í•© ë³´ê³ ì„œ ì €ì¥: {report_file}")
    
    def run_all_experiments(self):
        """ëª¨ë“  ë„ë©”ì¸ ì¡°í•©ì— ëŒ€í•´ ì‹¤í—˜ ì‹¤í–‰"""
        
        print("ğŸ¢ Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© SDA-U ì‹¤í—˜ ì‹œì‘!")
        print(f"ğŸ“Š ì´ {len(self.domain_combinations)}ê°œ ì‹¤í—˜ ì˜ˆì •")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.results_dir}/")
        
        start_time = time.time()
        successful_experiments = 0
        
        for i, (source, target, description) in enumerate(self.domain_combinations, 1):
            print(f"\nğŸ”¢ ì§„í–‰ìƒí™©: {i}/{len(self.domain_combinations)}")
            
            success, result_data = self.run_single_experiment(source, target, description)
            
            if success:
                successful_experiments += 1
                print(f"âœ… {i}ë²ˆì§¸ ì‹¤í—˜ ì„±ê³µ!")
            else:
                print(f"âŒ {i}ë²ˆì§¸ ì‹¤í—˜ ì‹¤íŒ¨!")
            
            # ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ì‹¤í—˜ì´ ì¤‘ë‹¨ë˜ì–´ë„ ê²°ê³¼ ë³´ì¡´)
            if self.all_results:
                self.create_performance_table()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\n{'='*80}")
        print("ğŸ‰ Office-31 ì „ì²´ ì‹¤í—˜ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µí•œ ì‹¤í—˜: {successful_experiments}/{len(self.domain_combinations)}")
        print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"{'='*80}")
        
        # ìµœì¢… ê²°ê³¼ ì •ë¦¬
        if self.all_results:
            self.print_performance_summary()
            self.create_performance_table()
            self.save_comprehensive_report()
        else:
            print("âŒ ì„±ê³µí•œ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸ¢ Office-31 ì „ì²´ ë„ë©”ì¸ ì¡°í•© SDA-U ì‹¤í—˜")
    print("=" * 60)
    
    # ì‹¤í—˜ ê´€ë¦¬ì ìƒì„±
    experiment_manager = Office31FullExperiments()
    
    print("\nì‹¤í–‰í•  ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ì „ì²´ ì‹¤í—˜ ì‹¤í–‰ (6ê°œ ë„ë©”ì¸ ì¡°í•©)")
    print("2. ê°œë³„ ì‹¤í—˜ ì„ íƒ")
    print("3. ê¸°ì¡´ ê²°ê³¼ ë¶„ì„")
    
    try:
        choice = input("\nì„ íƒ (1-3): ").strip()
        
        if choice == "1":
            # ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
            print("\nâš ï¸ ì „ì²´ ì‹¤í—˜ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
            if confirm == 'y':
                experiment_manager.run_all_experiments()
            else:
                print("ì‹¤í—˜ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                
        elif choice == "2":
            # ê°œë³„ ì‹¤í—˜ ì„ íƒ
            print("\në„ë©”ì¸ ì¡°í•©ì„ ì„ íƒí•˜ì„¸ìš”:")
            for i, (source, target, desc) in enumerate(experiment_manager.domain_combinations, 1):
                print(f"{i}. {desc}")
            
            exp_choice = int(input(f"\nì„ íƒ (1-{len(experiment_manager.domain_combinations)}): ")) - 1
            if 0 <= exp_choice < len(experiment_manager.domain_combinations):
                source, target, description = experiment_manager.domain_combinations[exp_choice]
                success, result_data = experiment_manager.run_single_experiment(source, target, description)
                
                if success:
                    print("âœ… ì‹¤í—˜ ì™„ë£Œ!")
                    experiment_manager.print_performance_summary()
                else:
                    print("âŒ ì‹¤í—˜ ì‹¤íŒ¨!")
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                
        elif choice == "3":
            # ê¸°ì¡´ ê²°ê³¼ ë¶„ì„
            results_dir = Path('office31_results')
            if results_dir.exists():
                result_files = list(results_dir.glob('*_results.json'))
                if result_files:
                    print(f"\nğŸ“Š ë°œê²¬ëœ ê²°ê³¼ íŒŒì¼: {len(result_files)}ê°œ")
                    
                    # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ
                    for result_file in result_files:
                        try:
                            with open(result_file, 'r', encoding='utf-8') as f:
                                result_data = json.load(f)
                            
                            exp_info = result_data.get('experiment_info', {})
                            experiment_manager.all_results.append({
                                'experiment_name': exp_info.get('experiment_name', 'Unknown'),
                                'source_dataset': exp_info.get('source_dataset', 'Unknown'),
                                'target_dataset': exp_info.get('target_dataset', 'Unknown'),
                                'description': exp_info.get('description', 'Unknown'),
                                'execution_time': exp_info.get('execution_time_seconds', 0),
                                'result_data': result_data
                            })
                        except Exception as e:
                            print(f"âš ï¸ {result_file} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    if experiment_manager.all_results:
                        experiment_manager.print_performance_summary()
                        experiment_manager.create_performance_table()
                    else:
                        print("âŒ ìœ íš¨í•œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("âŒ ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main() 