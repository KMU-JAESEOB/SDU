지금은 office31 데이터셋으로 실험해볼꺼야. 
지금 내가 요청한 부분이 잘 구현되어있는지 확인해주고, 
여기에서 stastus 를 프린트 너무 많이 하지마. 
그냥 깔끔하게, 성능만 각 에폭 또는 일정 에폭마다 잘 보이면 될꺼같아. 
내가 원하는 부분은 
결국 타겟 도메인에서 샘플을 선정하는거야 내가 제안하는 방법으로. 이전에 클래스를 미리 정해서 알려주게 했는데 그것도 쓰지말고, 그냥 내 방법으로 제안하는 샘플링을 통해서 먼저 타겟 도메인에서 샘플링을 했으면 좋겠어. 이때 내가 제안하는 샘플링 방법이 어떻게 보면 클래스가 균등하게 샘플링 되지 않게 만들어져있나????? 

<내 방법> 
언러닝이 완료된 모델 $\theta'$을 최소한의 비용으로 타겟 도메인 $D_T$에 효과적으로 적응시키기 위해, 전체 $D_T$ 중 가장 정보 가치가 높은 핵심 부분집합 $D_T^{\text{sub}}$를 선정한다. 이를 위해, 본 연구에서는 AlignSet의 철학에 능동 학습의 기준을 결합한 하이브리드 스코어링 함수 $S(x)$를 제안한다.

\paragraph{AlignSet 점수: 유용성과 다양성의 조화}
AlignSet\cite{AlignSet2025}은 좋은 부분집합이 '탐험'과 '활용'의 균형을 맞춰야 한다는 아이디어에 기반한다.
\begin{itemize} 
    \item \textbf{유용성 (Utility) $I(x;\theta')$}: 모델이 특정 샘플  $x$를 얼마나 '잘 이해하고 있는지'를 나타내는 지표로, 모델의 예측을 통해 생성한 의사 레이블(pseudo-label) $\hat{y}$에 대한 손실 값의 음수로 정의한다 ($I(x;\theta') = -\mathcal{L}((x, \hat{y}), \theta')$).
    \item \textbf{다양성 (Diversity) $\mathrm{div}(x, D_T^{\text{sub}})$}: 후보 샘플 $x$가 이미 선택된 부분집합 $D_T^{\text{sub}}$에 얼마나 새로운 정보를 추가하는지를 측정한다. 특징 공간에서 $x$와 $D_T^{\text{sub}}$ 내 모든 샘플 간의 최대 유사도로부터의 거리로 정의한다: $\mathrm{div}(x, D_T^{\text{sub}}) = 1 - \max_{s \in D_T^{\text{sub}}} k(f_{\theta'}(x), f_{\theta'}(s))$.
\end{itemize}
이 둘을 결합한 AlignSet 점수 $u(x) = \lambda_u \cdot I(x;\theta') + (1-\lambda_u) \cdot \mathrm{div}(x, D_T^{\text{sub}})$를 계산한다.

\paragraph{능동 학습 보강: 불확실성 기반 샘플링}
모델의 '약점'을 직접 공략하기 위해, 예측 불확실성이 가장 높은 샘플을 추가로 고려한다. 불확실성은 예측 확률분포의 **엔트로피(Entropy)**로 측정한다.
\begin{equation}
    H(x) = -\sum_{c=1}^{C} p_{\theta'}(y=c|x) \log p_{\theta'}(y=c|x)
\end{equation}
\paragraph{최종 큐레이션 점수}
최종적으로, 각 타겟 샘플 $x$에 대한 큐레이션 점수 $S(x) = u(x) + \beta \cdot H(x)$를 계산하여, 점수가 높은 순서대로 $D_T^{\text{sub}}$를 구성한다. 

그리고 여기에서, 머신 언러닝을 해야해. 머신 언러닝은 결국 잘 학습된 모델에서 소스 도메인의 샘플을 활용해서 소스 도메인의 성능을 희생하고 타겟 도메인의 성능을 올리자는 방법이자나. 
그럼 이 방법을 같이 활용해서 성능을 잘 뽑아주게 해야해. 
이때 소스 샘플 선별하는 방법과 머신 언러닝 방법은 내 방법을 참조해줘

<내 방법>
\subsection{1단계: 삭제 샘플 선정 (Forget Set Selection)}
이 단계는 소스 데이터 $D_S=\{(x_i,y_i)\}_{i=1}^{N}$ 중, 타겟 도메인 $D_T$ 적응에 해가 되는 \emph{삭제 후보} $D^f$와 각 샘플의 유해성 점수를 계산한다.

\paragraph{영향도 기반 필터링 (Influence-based Filtering)}
소스 샘플 $z_i \in D_S$가 임의의 타겟 배치 $D_T^{\text{batch}} \subset D_T$의 평균 손실에 미치는 \emph{영향도} $\mathcal{I}_{\mathrm{up}}(z_i, D_T^{\text{batch}})$를 계산한다.
\begin{equation}
    \mathcal{I}_{\mathrm{up}}(z_i, D_T^{\text{batch}})\;=\;-\nabla_{\theta} \mathcal{L}(D_T^{\text{batch}},\theta)^{\top} \mathbf{H}_{\theta}^{-1}\, \nabla_{\theta} \mathcal{L}(z_i,\theta)
\end{equation}
여기서 $\mathbf{H}_{\theta}^{-1}$는 헤시안 역행렬이다. 계산된 영향도 값이 음수($\mathcal{I}_{\mathrm{up}}<0$)인 샘플은 타겟 적응에 해롭다고 판단하여 삭제 후보 $D^f$에 포함시킨다.

\subsection{2단계: 선택적 언러닝 (Selective Unlearning)}
이 단계에서는 식별된 삭제 후보 $D^f$의 정보를 모델에서 제거한다. 본 논문에서는 기존의 직교 언러닝을 개선한 \textbf{동적 직교성 스케일링(DOS)}을 제안한다.

\paragraph{기존 직교 언러닝 (Orthogonal Gradient Unlearning)}
기존 방식은 삭제 세트 $D^f$의 평균 기울기 $\mathbf{g}_f$와 유지 세트 $D^r$의 평균 기울기 $\bar{\mathbf{g}}_r$를 이용한다. $\mathbf{g}_f$에서 $\bar{\mathbf{g}}_r$ 방향 성분을 제거하여, 유지할 지식에 대한 손실을 최소화하면서 삭제할 지식에 대한 손실만 극대화한다.
\begin{align}
    \tilde{\mathbf{g}}_f &\;=\; \mathbf{g}_f-\frac{\mathbf{g}_f^{\top}\bar{\mathbf{g}}_r}{\lVert\bar{\mathbf{g}}_r\rVert^{2}}\,\bar{\mathbf{g}}_r \\
    \theta &\leftarrow \theta + \eta\,\tilde{\mathbf{g}}_f
\end{align}
이 방식은 $D^f$ 내 모든 샘플을 동일하게 취급하는 한계가 있다.

\paragraph{동적 직교성 스케일링 (DOS) (본 연구 제안)}
DOS는 1단계에서 계산한 영향도 값 $\mathcal{I}_{\mathrm{up}}$을 언러닝 강도에 직접 반영한다. 더 해로운 샘플일수록 더 강하게 잊도록 가중치를 부여한다. 먼저, 각 삭제 샘플 $z_i \in D^f$에 대해 유해성 가중치 $w_i = -\mathcal{I}_{\mathrm{up}}(z_i, D_T^{\text{batch}})$를 정의하고, 이를 정규화($\hat{w}_i = w_i / \sum_{j \in D^f} w_j$)하여 가중치가 적용된 삭제 기울기 $\mathbf{g}_f^{\text{weighted}}$를 계산한다.
\begin{equation}
    \mathbf{g}_f^{\text{weighted}} = \sum_{z_i \in D^f} \hat{w}_i \cdot \nabla_{\theta}\mathcal{L}(z_i, \theta)
\end{equation}
이제, 이 가중 기울기에 대해 직교 언러닝을 수행한다.
\begin{align}
    \tilde{\mathbf{g}}_f^{\text{weighted}} &\;=\; \mathbf{g}_f^{\text{weighted}}-\frac{(\mathbf{g}_f^{\text{weighted}})^{\top}\bar{\mathbf{g}}_r}{\lVert\bar{\mathbf{g}}_r\rVert^{2}}\,\bar{\mathbf{g}}_r \\
    \theta &\leftarrow \theta + \eta\,\tilde{\mathbf{g}}_f^{\text{weighted}}
\end{align}
이 방식을 통해, 언러닝 과정의 정밀성과 효율성을 극대화한다. 

인제 거의 다 왔어. 이것을 단 한단계만 수행하는게 아니라 계속 수행해야해. 내가 지정한 에폭만큼. 그러니깐 내가 원하는 바는 먼저, 
1 전체 소스 도메인 데이터로 소스 도메인 분류 모델 학습 
 - 이후에는 잘 학습된 소스 도메인 모델을 가지고 와서, 활용할 예정. 재학습 안하게
2. 타겟 도메인에서 내가 제안하는 샘플선별 방법으로 타겟 도메인 샘플 선별 
3. 타겟 도메인 샘플로 모델 학습 실행
4. 실행 도중, 성능 상 교착지점이 발생 (config 파일에서 지정할 수 있도록 해야함) 
5. 교착 지점에서 머신 언러닝으로 소스도메인 성능을 약간 희생하면서 타겟 도메인의 성능을 높이도록 함. 이때 소스 도메인 샘플을 뽑고, 머신 언러닝 해야함
6. 다시 타겟 도메인 모델을 타겟 도메인 샘플로 학습
7. 실행 도중 성능 상 교착 지점 발생 
8. 소스 도메인 샘플 선별 (내가 제안하는 방법으로), 머신 언러닝 방법 수행
9. 이 과정을 계속 반복

- 이 과정에서 성능상 추적이 되도록 log 파일 만들고 성능을 기록해야함 
- 가장 좋은 타겟 도메인 모델 성능을 추적할 수 있어야함 (즉 모델 저장 필요)
- 너무 많은 stasuts 창 출력은 머리 아픔. 그냥 각 에폭마다 소스도메인과 타겟 도메인에서 현재 성능을 이떻게 나오고 있는지 잘 보여주면 될꺼 같음
 - 타겟 도메인 샘플의 수는 내가 지정할 수 있게 해야함. 100개에서부터 시작해서 증가시켜나갈거임. 

ㅇ;라ㅓ
