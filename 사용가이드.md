# ğŸ¯ ì™„ì „ ê°ì²´ì§€í–¥ SDA-U ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **SDA-U (Selective Domain Adaptation with Unlearning)** ì•Œê³ ë¦¬ì¦˜ì„ ì™„ì „ ê°ì²´ì§€í–¥ìœ¼ë¡œ ë¦¬íŒ©í† ë§í•œ ë²„ì „ì…ë‹ˆë‹¤.

### ğŸ—ï¸ ì£¼ìš” ê°œì„ ì‚¬í•­

1. **ì™„ì „í•œ ê°ì²´ì§€í–¥ ì„¤ê³„**: ëª¨ë“  ê¸°ëŠ¥ì´ í´ë˜ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ìº¡ìŠí™”
2. **ì„¤ì • íŒŒì¼ ë¶„ë¦¬**: `config.json`ìœ¼ë¡œ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì™¸ë¶€ ê´€ë¦¬
3. **ì¤‘ë³µ í•¨ìˆ˜ í†µí•©**: ê¸°ëŠ¥ë³„ë¡œ í•˜ë‚˜ì˜ ìµœì í™”ëœ êµ¬í˜„ì²´ë§Œ ìœ ì§€
4. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: ëª¨ë“ˆí™” ë° ì¸í„°í˜ì´ìŠ¤ í‘œì¤€í™”

### ğŸ”§ í•µì‹¬ í´ë˜ìŠ¤ êµ¬ì¡°

```
ğŸ“‚ SDA-U ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ë“¤
â”œâ”€â”€ ğŸ¯ SDAUAlgorithm         # ë©”ì¸ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤
â”œâ”€â”€ âš™ï¸ SDAUConfig            # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ ğŸ¤– ModelManager          # ëª¨ë¸ ìƒì„±/ì €ì¥/ë¡œë”©
â”œâ”€â”€ ğŸ“Š DataManager           # ë°ì´í„°ì…‹ ë¡œë”©
â”œâ”€â”€ ğŸ¯ TargetSampleSelector  # íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„
â”œâ”€â”€ ğŸ§® InfluenceCalculator   # ì˜í–¥ë„ ê³„ì‚° (í—¤ì‹œì•ˆ/ê°„ë‹¨)
â”œâ”€â”€ ğŸŒ™ UnlearningEngine      # ì–¸ëŸ¬ë‹ ì—”ì§„ (ì ì§„ì /ê°„ë‹¨)
â””â”€â”€ ğŸ‹ï¸ ModelTrainer         # ëª¨ë¸ í›ˆë ¨
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì • íŒŒì¼ ê´€ë¦¬

**ëª¨ë“  ì‹¤í—˜ ì„¤ì •ì€ `config.json` íŒŒì¼ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤:**

```json
{
  "training": {
    "batch_size": 32,
    "learning_rate": 2e-4,
    "max_epochs": 500,
    "patience": 30
  },
  "target_selection": {
    "budget_percent": 5,
    "selection_method": "balanced_uncertainty"
  },
  "influence_calculation": {
    "method": "hessian_lissa",
    "num_samples": 200
  },
  "unlearning": {
    "method": "gentle_dos",
    "num_steps": 5,
    "gentle_factor": 0.3
  }
}
```

### 2. ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰

```bash
# Office-31 ì‹¤í—˜
python main.py --dataset Office31 --source_domain Amazon --target_domain Webcam

# Office-Home ì‹¤í—˜
python main.py --dataset OfficeHome --source_domain Art --target_domain Clipart

# ì»¤ìŠ¤í…€ ì„¤ì • íŒŒì¼ ì‚¬ìš©
python main.py --dataset Office31 --source_domain Amazon --target_domain Webcam --config my_config.json
```

### 3. í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

```python
from main import SDAUAlgorithm

# SDA-U ì•Œê³ ë¦¬ì¦˜ ì´ˆê¸°í™”
sda_u = SDAUAlgorithm(config_path="config.json")

# ì‹¤í—˜ ì‹¤í–‰
results = sda_u.run_experiment(
    dataset="Office31",
    source_domain="Amazon", 
    target_domain="Webcam"
)

# ê²°ê³¼ í™•ì¸
print(f"ìµœê³  ì„±ëŠ¥: {results.best_target_acc:.2f}%")
print(f"ì–¸ëŸ¬ë‹ íšŸìˆ˜: {results.unlearning_count}íšŒ")
```

## âš™ï¸ ì„¤ì • íŒŒì¼ ìƒì„¸ ê°€ì´ë“œ

### ğŸ¯ íƒ€ê²Ÿ ìƒ˜í”Œ ì„ ë³„ ì„¤ì •

```json
"target_selection": {
  "budget_percent": 5,                    // íƒ€ê²Ÿ ìƒ˜í”Œ ë¹„ìœ¨ (%)
  "selection_method": "balanced_uncertainty", // ì„ ë³„ ë°©ë²•
  "uncertainty_threshold": 0.5,           // ë¶ˆí™•ì‹¤ì„± ì„ê³„ê°’
  "min_samples_per_class": 1              // í´ë˜ìŠ¤ë‹¹ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
}
```

**ì„ ë³„ ë°©ë²• ì˜µì…˜:**
- `"balanced_uncertainty"`: í´ë˜ìŠ¤ë³„ ê· ë“± ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ì„ ë³„ (ê¶Œì¥)
- `"random"`: ëœë¤ ì„ ë³„

### ğŸ§® ì˜í–¥ë„ ê³„ì‚° ì„¤ì •

```json
"influence_calculation": {
  "method": "hessian_lissa",              // ì˜í–¥ë„ ê³„ì‚° ë°©ë²•
  "num_samples": 200,                     // í‰ê°€í•  ì†ŒìŠ¤ ìƒ˜í”Œ ìˆ˜
  "damping": 0.01,                        // í—¤ì‹œì•ˆ ì •ê·œí™” íŒŒë¼ë¯¸í„°
  "lissa_iterations": 10,                 // LiSSA ë°˜ë³µ íšŸìˆ˜
  "max_influence_samples": 50             // ìµœëŒ€ ìœ í•´ ìƒ˜í”Œ ìˆ˜
}
```

**ì˜í–¥ë„ ê³„ì‚° ë°©ë²•:**
- `"hessian_lissa"`: í—¤ì‹œì•ˆ ê¸°ë°˜ ì •í™•í•œ ì˜í–¥ë„ (ê¶Œì¥, ëŠë¦¼)
- `"simple"`: ê°„ë‹¨í•œ ì˜í–¥ë„ ê³„ì‚° (ë¹ ë¦„, ëœ ì •í™•)

### ğŸŒ™ ì–¸ëŸ¬ë‹ ì„¤ì •

```json
"unlearning": {
  "method": "gentle_dos",                 // ì–¸ëŸ¬ë‹ ë°©ë²•
  "num_steps": 5,                         // ì–¸ëŸ¬ë‹ ìŠ¤í… ìˆ˜
  "learning_rate": 5e-6,                  // ì–¸ëŸ¬ë‹ í•™ìŠµë¥ 
  "gentle_factor": 0.3,                   // ë¶€ë“œëŸ¬ìš´ ì •ë„ (0-1)
  "projection_conservative": 0.8,         // ë³´ìˆ˜ì  íˆ¬ì˜ ê³„ìˆ˜
  "performance_drop_threshold": 5.0,      // ì„±ëŠ¥ í•˜ë½ ì„ê³„ê°’ (%)
  "orthogonal_projection": true           // ì§êµ íˆ¬ì˜ ì‚¬ìš© ì—¬ë¶€
}
```

**ì–¸ëŸ¬ë‹ ë°©ë²•:**
- `"gentle_dos"`: ì ì§„ì ì´ê³  ë¶€ë“œëŸ¬ìš´ DOS ì–¸ëŸ¬ë‹ (ê¶Œì¥)
- `"simple_dos"`: ê°„ë‹¨í•œ DOS ì–¸ëŸ¬ë‹

### ğŸ‹ï¸ í›ˆë ¨ ì„¤ì •

```json
"training": {
  "batch_size": 32,                       // ë°°ì¹˜ í¬ê¸°
  "learning_rate": 2e-4,                  // í•™ìŠµë¥ 
  "weight_decay": 1e-4,                   // L2 ì •ê·œí™” ê°•ë„
  "max_epochs": 500,                      // ìµœëŒ€ ì—í¬í¬
  "patience": 30,                         // ì •ì²´ í—ˆìš© ì—í¬í¬
  "epoch_chunk_size": 10,                 // ì—í¬í¬ ì²­í¬ í¬ê¸°
  "gradient_clip_norm": 1.0               // ê·¸ë¼ë””ì–¸íŠ¸ í´ë¦¬í•‘
}
```

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ê´€ë¦¬

### ê²°ê³¼ íŒŒì¼ êµ¬ì¡°

ì‹¤í—˜ ì‹¤í–‰ í›„ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:

```
ğŸ“ results/
â”œâ”€â”€ ğŸ“„ results.json              # ìµœì¢… ì‹¤í—˜ ê²°ê³¼
ğŸ“ models/Source2Target/
â”œâ”€â”€ ğŸ† best_model.pt             # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”œâ”€â”€ ğŸ“ final_model.pt            # ìµœì¢… ëª¨ë¸
â””â”€â”€ ğŸ“Š performance_history.json  # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
```

### ê²°ê³¼ ë¶„ì„

```python
import json

# ê²°ê³¼ ë¡œë”©
with open('results/results.json', 'r') as f:
    results = json.load(f)

print(f"ì´ˆê¸° ì„±ëŠ¥: {results['initial_target_acc']:.2f}%")
print(f"ìµœì¢… ì„±ëŠ¥: {results['final_target_acc']:.2f}%")
print(f"ìµœê³  ì„±ëŠ¥: {results['best_target_acc']:.2f}%")
print(f"ì„±ëŠ¥ í–¥ìƒ: {results['improvement']:.2f}%")
print(f"ì–¸ëŸ¬ë‹ íšŸìˆ˜: {results['unlearning_count']}íšŒ")

# ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë¡œë”©
with open('models/Amazon2Webcam/performance_history.json', 'r') as f:
    history = json.load(f)

# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
import matplotlib.pyplot as plt

epochs = [e for e in history['epoch'] if isinstance(e, int)]
target_accs = history['target_acc'][:len(epochs)]

plt.plot(epochs, target_accs)
plt.title('Target Domain Accuracy Over Time')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.show()
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ì‹¤í—˜

```python
# ì»¤ìŠ¤í…€ ì„¤ì • ìƒì„±
custom_config = {
    "training": {
        "max_epochs": 1000,      # ë” ê¸´ í›ˆë ¨
        "patience": 50           # ë” ë§ì€ patience
    },
    "unlearning": {
        "gentle_factor": 0.5,    # ë” ê°•í•œ ì–¸ëŸ¬ë‹
        "num_steps": 10          # ë” ë§ì€ ì–¸ëŸ¬ë‹ ìŠ¤í…
    }
}

# ì„¤ì • íŒŒì¼ ì €ì¥
import json
with open('aggressive_config.json', 'w') as f:
    json.dump(custom_config, f, indent=2)

# ì‹¤í–‰
sda_u = SDAUAlgorithm(config_path="aggressive_config.json")
results = sda_u.run_experiment("Office31", "Amazon", "Webcam")
```

### 2. ë°°ì¹˜ ì‹¤í—˜ ì‹¤í–‰

```python
def run_all_office31_experiments():
    """Office-31 ëª¨ë“  ì¡°í•© ì‹¤í—˜"""
    domains = ["Amazon", "Webcam", "DSLR"]
    sda_u = SDAUAlgorithm()
    
    all_results = {}
    
    for source in domains:
        for target in domains:
            if source != target:
                print(f"\nğŸ”„ ì‹¤í—˜: {source} â†’ {target}")
                
                results = sda_u.run_experiment("Office31", source, target)
                all_results[f"{source}2{target}"] = {
                    'best_acc': results.best_target_acc,
                    'improvement': results.improvement,
                    'unlearning_count': results.unlearning_count
                }
    
    return all_results

# ì‹¤í–‰
results = run_all_office31_experiments()
for exp, result in results.items():
    print(f"{exp}: {result['best_acc']:.2f}% (+{result['improvement']:.2f}%)")
```

### 3. ì„¤ì • íŒŒì¼ ë™ì  ìˆ˜ì •

```python
def create_sensitivity_analysis():
    """ì–¸ëŸ¬ë‹ ê°•ë„ì— ëŒ€í•œ ë¯¼ê°ë„ ë¶„ì„"""
    base_config = SDAUConfig("config.json")
    
    gentle_factors = [0.1, 0.3, 0.5, 0.7, 0.9]
    results = {}
    
    for factor in gentle_factors:
        # ì„¤ì • ë™ì  ìˆ˜ì •
        config_dict = base_config.config.copy()
        config_dict['unlearning']['gentle_factor'] = factor
        
        # ì„ì‹œ ì„¤ì • íŒŒì¼ ìƒì„±
        temp_config_path = f"temp_config_{factor}.json"
        with open(temp_config_path, 'w') as f:
            json.dump(config_dict, f, indent=2)
        
        # ì‹¤í—˜ ì‹¤í–‰
        sda_u = SDAUAlgorithm(config_path=temp_config_path)
        result = sda_u.run_experiment("Office31", "Amazon", "Webcam")
        
        results[factor] = result.best_target_acc
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_config_path)
    
    return results
```

## ğŸ›ï¸ ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ

### ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•œ ì„¤ì •

```json
{
  "training": {
    "max_epochs": 100,
    "patience": 10
  },
  "influence_calculation": {
    "method": "simple",
    "num_samples": 50
  },
  "unlearning": {
    "method": "simple_dos",
    "num_steps": 3
  },
  "performance": {
    "evaluation_batch_limit": 10
  }
}
```

### ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì •

```json
{
  "training": {
    "max_epochs": 1000,
    "patience": 50
  },
  "influence_calculation": {
    "method": "hessian_lissa",
    "num_samples": 500,
    "lissa_iterations": 20
  },
  "unlearning": {
    "method": "gentle_dos",
    "num_steps": 10,
    "gentle_factor": 0.2
  }
}
```

## ğŸš¨ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
   ```json
   "training": {
     "batch_size": 16        // ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   },
   "influence_calculation": {
     "num_samples": 100      // ìƒ˜í”Œ ìˆ˜ ì¤„ì´ê¸°
   }
   ```

2. **í›ˆë ¨ì´ ë„ˆë¬´ ëŠë¦¼**
   ```json
   "performance": {
     "evaluation_batch_limit": 5  // í‰ê°€ ë°°ì¹˜ ìˆ˜ ì¤„ì´ê¸°
   },
   "training": {
     "epoch_chunk_size": 5        // ì²­í¬ í¬ê¸° ì¤„ì´ê¸°
   }
   ```

3. **ì–¸ëŸ¬ë‹ í›„ ì„±ëŠ¥ ê¸‰ë½**
   ```json
   "unlearning": {
     "gentle_factor": 0.1,        // ë” ë¶€ë“œëŸ½ê²Œ
     "num_steps": 3               // ìŠ¤í… ìˆ˜ ì¤„ì´ê¸°
   }
   ```

### ë””ë²„ê¹… ëª¨ë“œ

```python
# ìƒì„¸ ë¡œê¹… í™œì„±í™”
import logging
logging.basicConfig(level=logging.DEBUG)

# ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
def monitor_experiment(config_path="config.json"):
    sda_u = SDAUAlgorithm(config_path)
    
    # ì‹¤í—˜ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
    import threading
    
    def run_exp():
        sda_u.run_experiment("Office31", "Amazon", "Webcam")
    
    thread = threading.Thread(target=run_exp)
    thread.start()
    
    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    import time
    while thread.is_alive():
        time.sleep(10)
        # ì¤‘ê°„ ê²°ê³¼ í™•ì¸ ë¡œì§
        print("ì‹¤í—˜ ì§„í–‰ ì¤‘...")
```

ì´ ê°€ì´ë“œë¥¼ í†µí•´ ì„¤ì • íŒŒì¼ë§Œ ìˆ˜ì •í•˜ì—¬ ëª¨ë“  ì‹¤í—˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‰½ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! 